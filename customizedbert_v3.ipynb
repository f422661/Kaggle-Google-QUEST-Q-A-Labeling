{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "customizedbert_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/f422661/google_qa/blob/master/customizedbert_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "KD6JKyGoW-3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('..'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz_vXPEMHfAL",
        "colab_type": "code",
        "outputId": "2ea8de76-0fda-48f9-cba0-760d271622e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jan 19 13:04:58 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZhO3xxuXtwR",
        "colab_type": "code",
        "outputId": "f2f2d4c8-d1d3-4c09-8777-34614c12af46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq49afG7bPLx",
        "colab_type": "code",
        "outputId": "6947176f-639d-4edb-ec9d-895a9267d49a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 31.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 5.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 34.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 40.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 48.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 44.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 26.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 29.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 19.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 18.3MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 18.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 30.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 37.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 45.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 50.7MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 54.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 59.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 56.2MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 57.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 59.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 41.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 41.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 41.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 41.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 41.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 41.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=41f700084784b787692e626c4d044ff79072526c609818af29a67ccd445c86ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjmAqfmUxDO",
        "colab_type": "code",
        "outputId": "5ca187d0-5d50-479b-d173-03a12a979525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install flashtext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flashtext\n",
            "  Downloading https://files.pythonhosted.org/packages/81/d8/2cd0656eae456d615c2f1efbcae8dfca2cb871a31f34ba8925aba47d5e09/flashtext-2.7.tar.gz\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9298 sha256=cd886cb2f366d0cda0ae2c87b58bc7daddfecd2ba40731b6ba299c50b6e226dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/db/d7/fe74f7cb8e5c3afed90fe6f4967c933a6f13d81ab6b3d3128c\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "",
        "_uuid": "",
        "id": "QHc6btamW-3h",
        "colab_type": "code",
        "outputId": "cb06c4d9-076e-40b3-9e31-297be00c0186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow.keras.backend as K\n",
        "import gc\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from flashtext import KeywordProcessor\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from scipy.stats import spearmanr\n",
        "from math import floor, ceil\n",
        "from transformers import AdamW,BertForSequenceClassification\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlYdOWB3W-3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/sample_submission.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/test.csv\")\n",
        "train = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/train.csv\")\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eboeli7RsNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# question = ['question_asker_intent_understanding', 'question_body_critical',\n",
        "#        'question_conversational', 'question_expect_short_answer',\n",
        "#        'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
        "#        'question_interestingness_others', 'question_interestingness_self',\n",
        "#        'question_multi_intent', 'question_not_really_a_question',\n",
        "#        'question_opinion_seeking', 'question_type_choice',\n",
        "#        'question_type_compare', 'question_type_consequence',\n",
        "#        'question_type_definition', 'question_type_entity',\n",
        "#        'question_type_instructions', 'question_type_procedure',\n",
        "#        'question_type_reason_explanation', 'question_type_spelling',\n",
        "#        'question_well_written']\n",
        "\n",
        "# train[question] = train.groupby([\"question_title\",\"question_body\"]).transform(\"mean\")[question]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIqdsDMrW-3l",
        "colab_type": "code",
        "outputId": "aeca738c-f24c-4d16-a940-3e410d2d2af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('train shape =', train.shape)\n",
        "print('test shape =', test.shape)\n",
        "\n",
        "output_categories = list(train.columns[11:])\n",
        "input_categories = list(train.columns[[1,2,5]])\n",
        "print('\\noutput categories:\\n\\t', output_categories)\n",
        "print('\\ninput categories:\\n\\t', input_categories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape = (6079, 41)\n",
            "test shape = (476, 11)\n",
            "\n",
            "output categories:\n",
            "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
            "\n",
            "input categories:\n",
            "\t ['question_title', 'question_body', 'answer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kN3He7eUd4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PUNCTS = {\n",
        "            '》', '〞', '¢', '‹', '╦', '║', '♪', 'Ø', '╩', '\\\\', '★', '＋', 'ï', '<', '?', '％', '+', '„', 'α', '*', '〰', '｟', '¹', '●', '〗', ']', '▾', '■', '〙', '↓', '´', '【', 'ᴵ',\n",
        "            '\"', '）', '｀', '│', '¤', '²', '‡', '¿', '–', '」', '╔', '〾', '%', '¾', '←', '〔', '＿', '’', '-', ':', '‧', '｛', 'β', '（', '─', 'à', 'â', '､', '•', '；', '☆', '／', 'π',\n",
        "            'é', '╗', '＾', '▪', ',', '►', '/', '〚', '¶', '♦', '™', '}', '″', '＂', '『', '▬', '±', '«', '“', '÷', '×', '^', '!', '╣', '▲', '・', '░', '′', '〝', '‛', '√', ';', '】', '▼',\n",
        "            '.', '~', '`', '。', 'ə', '］', '，', '{', '～', '！', '†', '‘', '﹏', '═', '｣', '〕', '〜', '＼', '▒', '＄', '♥', '〛', '≤', '∞', '_', '[', '＆', '→', '»', '－', '＝', '§', '⋅', \n",
        "            '▓', '&', 'Â', '＞', '〃', '|', '¦', '—', '╚', '〖', '―', '¸', '³', '®', '｠', '¨', '‟', '＊', '£', '#', 'Ã', \"'\", '▀', '·', '？', '、', '█', '”', '＃', '⊕', '=', '〟', '½', '』',\n",
        "            '［', '$', ')', 'θ', '@', '›', '＠', '｝', '¬', '…', '¼', '：', '¥', '❤', '€', '−', '＜', '(', '〘', '▄', '＇', '>', '₤', '₹', '∅', 'è', '〿', '「', '©', '｢', '∙', '°', '｜', '¡', \n",
        "            '↑', 'º', '¯', '♫', '#'\n",
        "          }\n",
        "\n",
        "\n",
        "mispell_dict = {\"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\",\n",
        "\"couldnt\" : \"could not\", \"didn't\" : \"did not\", \"doesn't\" : \"does not\",\n",
        "\"doesnt\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\", \"havent\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\", \"i'll\" : \"I will\", \"i'm\" : \"I am\", \"isn't\" : \"is not\", \"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\", \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \n",
        "\"shan't\" : \"shall not\", \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"shouldnt\" : \"should not\",\n",
        "\"that's\" : \"that is\", \"thats\" : \"that is\", \"there's\" : \"there is\", \"theres\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\", \"theyre\":  \"they are\", \"they've\" : \"they have\", \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\", \"what'll\" : \"what will\", \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\", \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\", \"wouldn't\" : \"would not\", \"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\", \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\", \"tryin'\":\"trying\"}\n",
        "\n",
        "\n",
        "def clean_punct(text):\n",
        "  text = str(text)\n",
        "  for punct in PUNCTS:\n",
        "    text = text.replace(punct, ' {} '.format(punct))\n",
        "  \n",
        "  return text\n",
        "\n",
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shmrs6ClUm8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kp = KeywordProcessor(case_sensitive=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEdvlp9MU-Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k, v in mispell_dict.items():\n",
        "    kp.add_keyword(k, v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXwwREPDU-Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'(\\&lt)|(\\&gt)', ' url ', text)\n",
        "    \n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', text)\n",
        "    text = kp.replace_keywords(text)\n",
        "    text = clean_punct(text)\n",
        "    text = re.sub(r'\\n\\r', ' ', text)\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ja3tPE_U-bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['clean_title'] = train['question_title'].apply(lambda x : preprocessing(x))\n",
        "train['clean_body'] = train['question_body'].apply(lambda x : preprocessing(x))\n",
        "train['clean_answer'] = train['answer'].apply(lambda x : preprocessing(x))\n",
        "\n",
        "test['clean_title'] = test['question_title'].apply(lambda x : preprocessing(x))\n",
        "test['clean_body'] = test['question_body'].apply(lambda x : preprocessing(x))\n",
        "test['clean_answer'] = test['answer'].apply(lambda x : preprocessing(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw-o2_9SW-3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_masks(tokens, max_seq_length):\n",
        "    \"\"\"Mask for padding\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def _get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    first_sep = True\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            if first_sep:\n",
        "                first_sep = False \n",
        "            else:\n",
        "                current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# def _get_segments_v2(tokens, max_seq_length):\n",
        "#     \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "#     if len(tokens)>max_seq_length:\n",
        "#         raise IndexError(\"Token length more than max seq length!\")\n",
        "#     segments = []\n",
        "#     current_segment_id = 0\n",
        "#     for token in tokens:\n",
        "#         segments.append(current_segment_id)\n",
        "#         if token == \"[SEP]\":\n",
        "#             current_segment_id += 1\n",
        "#     return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def _get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def _trim_input(title, question, answer, max_sequence_length, \n",
        "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
        "\n",
        "    t = tokenizer.tokenize(title)\n",
        "    q = tokenizer.tokenize(question)\n",
        "    a = tokenizer.tokenize(answer)\n",
        "    \n",
        "    t_len = len(t)\n",
        "    q_len = len(q)\n",
        "    a_len = len(a)\n",
        "\n",
        "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
        "        \n",
        "        if t_max_len > t_len:\n",
        "            t_new_len = t_len\n",
        "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
        "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
        "        else:\n",
        "            t_new_len = t_max_len\n",
        "      \n",
        "        if a_max_len > a_len:\n",
        "            a_new_len = a_len \n",
        "            q_new_len = q_max_len + (a_max_len - a_len)\n",
        "        elif q_max_len > q_len:\n",
        "            a_new_len = a_max_len + (q_max_len - q_len)\n",
        "            q_new_len = q_len\n",
        "        else:\n",
        "            a_new_len = a_max_len\n",
        "            q_new_len = q_max_len\n",
        "            \n",
        "            \n",
        "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
        "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
        "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
        "        \n",
        "        if t_len > t_new_len:\n",
        "            ind1 = floor(t_new_len/2)\n",
        "            ind2 = ceil(t_new_len/2)\n",
        "            t = t[:ind1]+t[-ind2:]\n",
        "        else:\n",
        "            t = t[:t_new_len]\n",
        "\n",
        "        if q_len > q_new_len:\n",
        "            ind1 = floor(q_new_len/2)\n",
        "            ind2 = ceil(q_new_len/2)\n",
        "            q = q[:ind1]+q[-ind2:]\n",
        "        else:\n",
        "            q = q[:q_new_len]\n",
        "\n",
        "        if a_len > a_new_len:\n",
        "            ind1 = floor(a_new_len/2)\n",
        "            ind2 = ceil(a_new_len/2)\n",
        "            a = a[:ind1]+a[-ind2:]\n",
        "        else:\n",
        "            a = a[:a_new_len]\n",
        "    \n",
        "    return t, q, a\n",
        "\n",
        "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
        "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
        "    \n",
        "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
        "\n",
        "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
        "    input_masks = _get_masks(stoken, max_sequence_length)\n",
        "    input_segments = _get_segments(stoken, max_sequence_length)\n",
        "\n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for _, instance in tqdm(df[columns].iterrows()):\n",
        "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
        "\n",
        "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
        "\n",
        "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
        "        input_ids.append(ids)\n",
        "        input_masks.append(masks)\n",
        "        input_segments.append(segments)\n",
        "        \n",
        "    return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)]\n",
        "\n",
        "\n",
        "def compute_output_arrays(df, columns):\n",
        "    return np.asarray(df[columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcJFuVXDW-3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "323A8fOJW-3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextDataset(torch.utils.data.TensorDataset):\n",
        "\n",
        "    def __init__(self, x_train, idxs, targets=None):\n",
        "        self.input_ids = x_train[0][idxs]\n",
        "        self.input_masks = x_train[1][idxs]\n",
        "        self.input_segments = x_train[2][idxs]\n",
        "        self.targets = targets[idxs] if targets is not None else np.zeros((x_train[0].shape[0], 30))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "#         x_train = self.x_train[idx]\n",
        "        input_ids =  self.input_ids[idx]\n",
        "        input_masks = self.input_masks[idx]\n",
        "        input_segments = self.input_segments[idx]\n",
        "\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        return input_ids, input_masks, input_segments, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ1oU5n_W-3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer,BertConfig,get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXqSLKNW-3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_weights = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCp7_1H-W-3x",
        "colab_type": "code",
        "outputId": "7fc1239b-ee48-450c-dcbd-9a71d092c864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "y_train = compute_output_arrays(train, output_categories)\n",
        "x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6079it [00:36, 165.74it/s]\n",
            "476it [00:02, 158.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSdXUpPRW-3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = BertConfig.from_pretrained(pretrained_weights) \n",
        "bert_config.num_labels = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlp16oXW-31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from transformers import BertPreTrainedModel,BertModel\n",
        "\n",
        "\n",
        "class CustomizedBert(BertPreTrainedModel):\n",
        "    r\"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "\n",
        "    Examples::\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
        "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(CustomizedBert, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        config.output_hidden_states=True\n",
        "        self.bert = BertModel(config)\n",
        "        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.linear1 = nn.Linear(config.hidden_size*2, config.hidden_size)\n",
        "        # self.bn = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.linear2 = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        avg_pool = torch.mean(outputs[0], 1)\n",
        "        max_pool, _ = torch.max(outputs[0], 1)\n",
        "        pooled_output = torch.cat((max_pool, avg_pool), 1)\n",
        "        pooled_output = F.relu(self.linear1(pooled_output))\n",
        "        logits = self.linear2(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITMu2nKrHqXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class callback:\n",
        "    def __init__(self):\n",
        "        self.score = list()\n",
        "        self.model = list()\n",
        "        self.data = list()\n",
        "    \n",
        "    def put(self, model,data, score):\n",
        "        self.score.append(score)\n",
        "        self.model.append(model)\n",
        "        self.data.append(data)\n",
        "\n",
        "    def get_model(self):\n",
        "        ind = np.argmin(self.score)\n",
        "        return self.model[ind]\n",
        "    def get_data(self):\n",
        "        ind = np.argmin(self.score)\n",
        "        return self.data[ind]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jYqd5JPW-33",
        "colab_type": "code",
        "outputId": "cd6f2687-667b-403b-d569-3aa3a84207e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "NFOLDS = 5\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 5\n",
        "SEED = 1112\n",
        "num_warmup_steps = 100\n",
        "lr = 5e-5\n",
        "\n",
        "\n",
        "gradient_accumulation_steps = 1\n",
        "seed_everything(SEED)\n",
        "\n",
        "model_list = list()\n",
        "\n",
        "\n",
        "y_oof = np.zeros((len(train), 30))\n",
        "test_pred = np.zeros((len(test), 30))\n",
        "\n",
        "kf = KFold(n_splits=NFOLDS, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n",
        "    \n",
        "    \n",
        "    print(f'fold {i+1}')\n",
        "    gc.collect()\n",
        "    \n",
        "    ## loader\n",
        "    train_loader = torch.utils.data.DataLoader(TextDataset(x_train, train_idx, y_train),batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n",
        "    \n",
        "\n",
        "    t_total = len(train_loader)//gradient_accumulation_steps*EPOCHS\n",
        "\n",
        "\n",
        "    net = CustomizedBert.from_pretrained(pretrained_weights, config=bert_config)\n",
        "    net.cuda()\n",
        "    \n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "    optimizer = AdamW(net.parameters(), lr = lr)\n",
        "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler\n",
        "\n",
        "    cb = callback()\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):  \n",
        "\n",
        "\n",
        "        \n",
        "        start_time = time.time()\n",
        "        avg_loss = 0.0\n",
        "        net.train()\n",
        "\n",
        "\n",
        "        for step, data in enumerate(train_loader):\n",
        "\n",
        "            # get the inputs\n",
        "            input_ids, input_masks, input_segments, labels = data\n",
        "\n",
        "\n",
        "            pred = net(input_ids = input_ids.long().cuda(),\n",
        "                             labels = None,\n",
        "                             attention_mask = input_masks.cuda(),\n",
        "                             token_type_ids = input_segments.long().cuda()\n",
        "                            )[0]\n",
        "            \n",
        "            \n",
        "            loss = loss_fn(pred, labels.cuda())\n",
        "        \n",
        "            avg_loss += loss.item()\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            loss.backward()\n",
        "\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "\n",
        "                # Calling the step function on an Optimizer makes an update to its parameters\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                \n",
        "        avg_val_loss = 0.0\n",
        "\n",
        "        valid_preds = np.zeros((len(valid_idx), 30))\n",
        "        true_label = np.zeros((len(valid_idx), 30))\n",
        "        \n",
        "        for j,data in enumerate(val_loader):\n",
        "\n",
        "            # get the inputs\n",
        "            input_ids, input_masks, input_segments, labels = data\n",
        "            pred = net(input_ids = input_ids.long().cuda(),\n",
        "                             labels = None,\n",
        "                             attention_mask = input_masks.cuda(),\n",
        "                             token_type_ids = input_segments.long().cuda()\n",
        "                            )[0]\n",
        "\n",
        "            loss_val = loss_fn(pred, labels.cuda())\n",
        "            avg_val_loss += loss_val.item()\n",
        "     \n",
        "            valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = torch.sigmoid(pred).cpu().detach().numpy()\n",
        "            true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels\n",
        "\n",
        "\n",
        "        elapsed_time = time.time() - start_time \n",
        "\n",
        "        score = 0\n",
        "        for i in range(30):\n",
        "          s = np.nan_to_num(\n",
        "                    spearmanr(true_label[:, i], valid_preds[:, i]).correlation / 30)\n",
        "          score += s\n",
        "\n",
        "        \n",
        "\n",
        "        print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f}\\t spearmanr={:.4f}\\t time={:.2f}s'.format(epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader),score, elapsed_time))\n",
        "\n",
        "        cb.put(net,valid_preds,avg_val_loss/len(val_loader))\n",
        "\n",
        "\n",
        "\n",
        "    model_list.append(cb.get_model())\n",
        "    y_oof[valid_idx] = cb.get_data()\n",
        "\n",
        "\n",
        "    result = list()\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            input_ids, input_masks, input_segments, labels = data\n",
        "            y_pred = net(input_ids = input_ids.long().cuda(),\n",
        "                                labels = None,\n",
        "                                attention_mask = input_masks.cuda(),\n",
        "                                token_type_ids = input_segments.long().cuda(),\n",
        "                            )[0]\n",
        "            result.extend(torch.sigmoid(y_pred).cpu().detach().numpy())\n",
        "            \n",
        "    test_pred += np.array(result)/NFOLDS\n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "Epoch 1/5 \t loss=0.4014\t val_loss=0.3793\t spearmanr=0.3480\t time=339.19s\n",
            "Epoch 2/5 \t loss=0.3656\t val_loss=0.3715\t spearmanr=0.3774\t time=338.86s\n",
            "Epoch 3/5 \t loss=0.3497\t val_loss=0.3671\t spearmanr=0.3956\t time=338.72s\n",
            "Epoch 4/5 \t loss=0.3352\t val_loss=0.3686\t spearmanr=0.3949\t time=338.52s\n",
            "Epoch 5/5 \t loss=0.3256\t val_loss=0.3694\t spearmanr=0.3933\t time=338.67s\n",
            "fold 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5 \t loss=0.4013\t val_loss=0.3792\t spearmanr=0.3440\t time=338.62s\n",
            "Epoch 2/5 \t loss=0.3661\t val_loss=0.3665\t spearmanr=0.3777\t time=338.80s\n",
            "Epoch 3/5 \t loss=0.3495\t val_loss=0.3633\t spearmanr=0.3893\t time=338.68s\n",
            "Epoch 4/5 \t loss=0.3338\t val_loss=0.3651\t spearmanr=0.3920\t time=338.73s\n",
            "Epoch 5/5 \t loss=0.3229\t val_loss=0.3656\t spearmanr=0.3920\t time=338.70s\n",
            "fold 3\n",
            "Epoch 1/5 \t loss=0.4013\t val_loss=0.3756\t spearmanr=0.3575\t time=338.53s\n",
            "Epoch 2/5 \t loss=0.3662\t val_loss=0.3677\t spearmanr=0.3877\t time=338.48s\n",
            "Epoch 3/5 \t loss=0.3500\t val_loss=0.3653\t spearmanr=0.3987\t time=338.64s\n",
            "Epoch 4/5 \t loss=0.3352\t val_loss=0.3656\t spearmanr=0.4040\t time=338.61s\n",
            "Epoch 5/5 \t loss=0.3253\t val_loss=0.3659\t spearmanr=0.4022\t time=338.54s\n",
            "fold 4\n",
            "Epoch 1/5 \t loss=0.4007\t val_loss=0.3806\t spearmanr=0.3588\t time=338.66s\n",
            "Epoch 2/5 \t loss=0.3656\t val_loss=0.3668\t spearmanr=0.3931\t time=338.60s\n",
            "Epoch 3/5 \t loss=0.3489\t val_loss=0.3644\t spearmanr=0.4003\t time=338.87s\n",
            "Epoch 4/5 \t loss=0.3334\t val_loss=0.3655\t spearmanr=0.4022\t time=338.75s\n",
            "Epoch 5/5 \t loss=0.3224\t val_loss=0.3676\t spearmanr=0.4009\t time=338.87s\n",
            "fold 5\n",
            "Epoch 1/5 \t loss=0.4017\t val_loss=0.3738\t spearmanr=0.3591\t time=338.84s\n",
            "Epoch 2/5 \t loss=0.3671\t val_loss=0.3695\t spearmanr=0.3872\t time=339.09s\n",
            "Epoch 3/5 \t loss=0.3512\t val_loss=0.3629\t spearmanr=0.3930\t time=339.03s\n",
            "Epoch 4/5 \t loss=0.3363\t val_loss=0.3636\t spearmanr=0.3977\t time=339.00s\n",
            "Epoch 5/5 \t loss=0.3262\t val_loss=0.3648\t spearmanr=0.3953\t time=340.69s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDCONI_-E4AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " with open(\"/content/drive/My Drive/qa_model/model01193.pkl\",\"wb\") as f:\n",
        "    pickle.dump(model_list,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWYS2xohfu4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oof_score = 0\n",
        "for i in range(30):\n",
        "    oof_score += np.nan_to_num(\n",
        "            spearmanr(y_train[:, i], y_oof[:, i]).correlation / 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxx6YCuK3uMO",
        "colab_type": "code",
        "outputId": "0c22c38f-d828-4246-8539-960563f6d7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Out of folds score = {}\",oof_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of folds score = {} 0.3923216616167369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VViu-mZKW-34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.loc[:, output_categories] = test_pred\n",
        "sample_submission.to_csv('/content/drive/My Drive/qa_submission/submission01193.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW8fLMuBW-36",
        "colab_type": "code",
        "outputId": "9977d327-d095-4323-8a55-17493e2d16df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI4DwGIphUSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = CustomizedBert.from_pretrained(pretrained_weights, config=bert_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDI70vaCgVri",
        "colab_type": "code",
        "outputId": "4c146022-dd6d-419c-f88e-9ba775d5cf75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
        "outputs = net(input_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iml46F4riDHM",
        "colab_type": "code",
        "outputId": "f8a343d8-0eb8-4e08-f1b6-6fd1a0f41326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outputs[2][-1].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLlbo3UkiEjU",
        "colab_type": "code",
        "outputId": "e9f166ca-8c45-4370-f15c-b79b28254849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outputs[2][-1][:,0].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1LjrOihiMNr",
        "colab_type": "code",
        "outputId": "645c789e-3f64-4072-88ca-3c731dce60ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f9c260299c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties and _CudaDeviceProperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mDoes\u001b[0m \u001b[0mnothing\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    192\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95bXQm-tRDZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtGD1poLR6xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.current_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xdJaYAYSEH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}