{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"customizedbert_v3_qa_inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c34cb315be6c49c38a801cf69d1cafcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_419f823159234c70b068d67df2f1ea82","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_10cf3b42bc544d24ba1b9a6c7cff33ba","IPY_MODEL_0712a17b67b94cd3b3b08df02cf7d4e8"]}},"419f823159234c70b068d67df2f1ea82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10cf3b42bc544d24ba1b9a6c7cff33ba":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0b491fc36cee4527bdd8ba09d3f079a1","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e13d4399c3e545e9b023b1a48e19aac9"}},"0712a17b67b94cd3b3b08df02cf7d4e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aadbfdb6da584f4a908fc0db496da3db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 415kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12f8b5dcab1f4676b1e9611941134a0b"}},"0b491fc36cee4527bdd8ba09d3f079a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e13d4399c3e545e9b023b1a48e19aac9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aadbfdb6da584f4a908fc0db496da3db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"12f8b5dcab1f4676b1e9611941134a0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"KD6JKyGoW-3a","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('..'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz_vXPEMHfAL","colab_type":"code","outputId":"7888bf74-b168-4767-aaef-732aad0ac2dc","executionInfo":{"status":"ok","timestamp":1580909626511,"user_tz":-480,"elapsed":5757,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Wed Feb  5 13:33:43 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ZhO3xxuXtwR","colab_type":"code","outputId":"62e7643f-e104-44e4-a3fe-0c4d21a9f325","executionInfo":{"status":"ok","timestamp":1580909647219,"user_tz":-480,"elapsed":25946,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uq49afG7bPLx","colab_type":"code","outputId":"ad70db82-5029-4d48-a61e-f385df53d26f","executionInfo":{"status":"ok","timestamp":1580909659361,"user_tz":-480,"elapsed":11188,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":646}},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\r\u001b[K     |▊                               | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 1.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 2.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 2.6MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\r\u001b[K     |▎                               | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 8.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 19.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 19.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=746a0812931352e6ed598174be39b9a7c886c94bb1d1cc210b580db03ee3a88b\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"","_uuid":"","id":"QHc6btamW-3h","colab_type":"code","outputId":"5917da9e-f876-4d9a-c82b-46c49b3d6964","executionInfo":{"status":"ok","timestamp":1580909664148,"user_tz":-480,"elapsed":15729,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import random\n","import pickle\n","import tensorflow.keras.backend as K\n","import gc\n","import time\n","import re\n","import os\n","import torch\n","from scipy.stats import spearmanr\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import KFold,StratifiedKFold\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","from transformers import AdamW,BertForSequenceClassification\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SlYdOWB3W-3j","colab_type":"code","colab":{}},"source":["sample_submission = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/sample_submission.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/test.csv\")\n","train = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/train.csv\")\n","\n","MAX_SEQUENCE_LENGTH = 512"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIqdsDMrW-3l","colab_type":"code","outputId":"8460796b-306b-41cf-9642-3f759fc2fb51","executionInfo":{"status":"ok","timestamp":1580909664937,"user_tz":-480,"elapsed":16177,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["print('train shape =', train.shape)\n","print('test shape =', test.shape)\n","\n","output_categories = list(train.columns[11:])\n","input_categories = list(train.columns[[1,2,5]])\n","print('\\noutput categories:\\n\\t', output_categories)\n","print('\\ninput categories:\\n\\t', input_categories)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["train shape = (6079, 41)\n","test shape = (476, 11)\n","\n","output categories:\n","\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n","\n","input categories:\n","\t ['question_title', 'question_body', 'answer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fw-o2_9SW-3n","colab_type":"code","colab":{}},"source":["def _get_masks(tokens, max_seq_length):\n","    \"\"\"Mask for padding\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","\n","def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            if first_sep:\n","                first_sep = False \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input_q(title, question,max_sequence_length, \n","                t_max_len=50, q_max_len=459):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","\n","    if (t_len+q_len+3) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            q_max_len = q_max_len + (t_max_len - t_len)\n","        else:\n","            t_new_len = t_max_len\n","      \n","\n","        q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+ q_new_len+3 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","            \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","    \n","    return t, q\n","\n","\n","def _trim_input(title, question, answer, max_sequence_length, \n","                t_max_len=30, q_max_len=239, a_max_len=239):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","        \n","\n","        ## for head + tail\n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","        if a_len > a_new_len:\n","            ind1 = floor(a_new_len/2)\n","            ind2 = ceil(a_new_len/2)\n","            a = a[:ind1]+a[-ind2:]\n","        else:\n","            a = a[:a_new_len]\n","    \n","    return t, q, a\n","\n","def _convert_to_bert_inputs(title, question, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    \n","    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n","\n","    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n","    input_masks = _get_masks(stoken, max_sequence_length)\n","    input_segments = _get_segments(stoken, max_sequence_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        t, q = _trim_input_q(t, q, max_sequence_length)\n","\n","        ids, masks, segments = _convert_to_bert_inputs(t, q, tokenizer, max_sequence_length)\n","        input_ids.append(ids)\n","        input_masks.append(masks)\n","        input_segments.append(segments)\n","        \n","    return [np.asarray(input_ids, dtype=np.int32), \n","            np.asarray(input_masks, dtype=np.int32), \n","            np.asarray(input_segments, dtype=np.int32)]\n","\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcJFuVXDW-3p","colab_type":"code","colab":{}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7_6-IFm2-ed","colab_type":"code","colab":{}},"source":["import torch\n","\n","def hard_sigmoid(x):\n","    \"\"\"\n","    Computes element-wise hard sigmoid of x.\n","    See e.g. https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/sigm.py#L279\n","    \"\"\"\n","    x = (0.2 * x) + 0.5\n","    x = torch.clamp(x, 0.000001, 0.999999)\n","    return x\n","\n","def postProcessing(x):\n","    x = torch.tensor(x)\n","    x = torch.cat((torch.sigmoid(x[:,:2]),hard_sigmoid(x[:,2].reshape(-1,1)),torch.sigmoid(x[:,3:11]),hard_sigmoid(x[:,11:13]),\\\n","                        torch.sigmoid(x[:,13].reshape(-1,1)),hard_sigmoid(x[:,14:16]),torch.sigmoid(x[:,16:])),1)\n","    \n","    return x.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"323A8fOJW-3r","colab_type":"code","colab":{}},"source":["class TextDataset(torch.utils.data.TensorDataset):\n","\n","    def __init__(self, x_train, idxs, targets=None):\n","        self.input_ids = x_train[0][idxs]\n","        self.input_masks = x_train[1][idxs]\n","        self.input_segments = x_train[2][idxs]\n","        self.targets = targets[idxs] if targets is not None else np.zeros((x_train[0].shape[0], 30))\n","\n","    def __getitem__(self, idx):\n","#         x_train = self.x_train[idx]\n","        input_ids =  self.input_ids[idx]\n","        input_masks = self.input_masks[idx]\n","        input_segments = self.input_segments[idx]\n","\n","        target = self.targets[idx]\n","\n","        return input_ids, input_masks, input_segments, target\n","\n","    def __len__(self):\n","        return len(self.input_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ1oU5n_W-3t","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer,BertConfig,get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TXqSLKNW-3v","colab_type":"code","outputId":"21b4b03f-9102-42e4-ca88-6736550a8ee5","executionInfo":{"status":"ok","timestamp":1580909667576,"user_tz":-480,"elapsed":17867,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["c34cb315be6c49c38a801cf69d1cafcf","419f823159234c70b068d67df2f1ea82","10cf3b42bc544d24ba1b9a6c7cff33ba","0712a17b67b94cd3b3b08df02cf7d4e8","0b491fc36cee4527bdd8ba09d3f079a1","e13d4399c3e545e9b023b1a48e19aac9","aadbfdb6da584f4a908fc0db496da3db","12f8b5dcab1f4676b1e9611941134a0b"]}},"source":["pretrained_weights = 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c34cb315be6c49c38a801cf69d1cafcf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UCp7_1H-W-3x","colab_type":"code","outputId":"dc4fc3e9-4267-481d-a557-5e6a9bece076","executionInfo":{"status":"ok","timestamp":1580909689682,"user_tz":-480,"elapsed":39818,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","y_train = compute_output_arrays(train, output_categories)\n","x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["6079it [00:20, 302.92it/s]\n","476it [00:01, 302.60it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cKlp16oXW-31","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import BertPreTrainedModel,BertModel\n","\n","\n","class CustomizedBert(torch.nn.Module):\n","\n","\n","    def __init__(self):\n","\n","        super(CustomizedBert, self).__init__()\n","        bert_config = BertConfig.from_pretrained(pretrained_weights) \n","        bert_config.output_hidden_states=True\n","        self.bert = BertModel.from_pretrained(pretrained_weights)\n","        self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n","        self.linear1 = nn.Linear(768*2, 21)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","\n","        avg_pool = torch.mean(outputs[0], 1)\n","        max_pool, _ = torch.max(outputs[0], 1)\n","        pooled_output = self.dropout(torch.cat((max_pool, avg_pool), 1))\n","        logits = self.linear1(pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITMu2nKrHqXL","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","class callback:\n","    def __init__(self):\n","        self.score = list()\n","        self.model = list()\n","        self.data = list()\n","    \n","    def put(self, model,data, score):\n","        self.score.append(score)\n","        self.model.append(model)\n","        self.data.append(data)\n","\n","    def get_model(self):\n","        ind = np.argmin(self.score)\n","        return self.model[ind]\n","    def get_data(self):\n","        ind = np.argmin(self.score)\n","        return self.data[ind]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0akvQFUbGXc7","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/model0202_q2.pkl\",\"rb\") as f:\n","    model_list = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_ia25HEG4mN","colab_type":"code","outputId":"3a3c61c2-6b2e-4f33-fe2d-d7a8da82d685","executionInfo":{"status":"ok","timestamp":1580909714755,"user_tz":-480,"elapsed":64103,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(model_list)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"0jYqd5JPW-33","colab_type":"code","outputId":"03821d85-b955-4ebe-ee38-681fb20ba5ea","executionInfo":{"status":"ok","timestamp":1580909885295,"user_tz":-480,"elapsed":234198,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["NFOLDS = 5\n","BATCH_SIZE = 4\n","EPOCHS = 4\n","SEED = 9638\n","num_warmup_steps = 100\n","lr = 3e-5\n","\n","\n","gradient_accumulation_steps = 1\n","seed_everything(SEED)\n","\n","\n","y_oof_q = np.zeros((len(train), 21))\n","test_pred_q = np.zeros((len(test), 21))\n","\n","kf = KFold(n_splits=NFOLDS, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n","    \n","\n","    print(f'fold {i+1}')\n","    gc.collect()\n","    \n","    ## loader\n","    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    net = model_list[i]\n","    net.cuda()\n","\n","\n","    valid_preds = np.zeros((len(valid_idx), 21))\n","        \n","    net.eval()\n","    for j,data in enumerate(val_loader):\n","\n","        # get the inputs\n","        input_ids, input_masks, input_segments, labels = data\n","        pred = net(input_ids = input_ids.long().cuda(),\n","                        labels = None,\n","                        attention_mask = input_masks.cuda(),\n","                        token_type_ids = input_segments.long().cuda()\n","                        )[0]\n","\n","\n","        valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n","\n","    y_oof_q[valid_idx] = valid_preds\n","    \n","    result = list()\n","\n","\n","    net.eval()\n","    with torch.no_grad():\n","        for data in test_loader:\n","            input_ids, input_masks, input_segments, labels = data\n","            y_pred = net(input_ids = input_ids.long().cuda(),\n","                                labels = None,\n","                                attention_mask = input_masks.cuda(),\n","                                token_type_ids = input_segments.long().cuda(),\n","                            )[0]\n","\n","            result.extend(y_pred.cpu().detach().numpy())\n","            \n","    test_pred_q += np.array(result)/NFOLDS\n","\n","\n","        \n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hbxoXSCjNaXk","colab_type":"code","colab":{}},"source":["def _get_masks(tokens, max_seq_length):\n","    \"\"\"Mask for padding\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","\n","def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            if first_sep:\n","                first_sep = False \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input(title, question, answer, max_sequence_length, \n","                t_max_len=30, q_max_len=239, a_max_len=239):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","        \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","        if a_len > a_new_len:\n","            ind1 = floor(a_new_len/2)\n","            ind2 = ceil(a_new_len/2)\n","            a = a[:ind1]+a[-ind2:]\n","        else:\n","            a = a[:a_new_len]\n","    \n","    return t, q, a\n","\n","def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    \n","    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n","\n","    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n","    input_masks = _get_masks(stoken, max_sequence_length)\n","    input_segments = _get_segments(stoken, max_sequence_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        t, q, a = _trim_input(t, q, a, max_sequence_length)\n","\n","        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n","        input_ids.append(ids)\n","        input_masks.append(masks)\n","        input_segments.append(segments)\n","        \n","    return [np.asarray(input_ids, dtype=np.int32), \n","            np.asarray(input_masks, dtype=np.int32), \n","            np.asarray(input_segments, dtype=np.int32)]\n","\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnq1ILlDNaco","colab_type":"code","outputId":"a0a84800-4604-4ff7-db6f-52790862c089","executionInfo":{"status":"ok","timestamp":1580909925849,"user_tz":-480,"elapsed":273760,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["6079it [00:36, 167.50it/s]\n","476it [00:03, 156.88it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Qn7Q9dGsNaf2","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import BertPreTrainedModel,BertModel\n","\n","\n","class CustomizedBert(torch.nn.Module):\n","\n","\n","    def __init__(self):\n","\n","        super(CustomizedBert, self).__init__()\n","        bert_config = BertConfig.from_pretrained(pretrained_weights) \n","        bert_config.output_hidden_states=True\n","        self.bert = BertModel.from_pretrained(pretrained_weights)\n","        self.dropout = nn.Dropout(bert_config.hidden_dropout_prob)\n","        self.linear1 = nn.Linear(768*2, 9)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","\n","        avg_pool = torch.mean(outputs[0], 1)\n","        max_pool, _ = torch.max(outputs[0], 1)\n","        pooled_output = self.dropout(torch.cat((max_pool, avg_pool), 1))\n","        logits = self.linear1(pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-eKI2ICDNaaq","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/model0202_a2.pkl\",\"rb\") as f:\n","    model_list = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSJdpArINaV4","colab_type":"code","outputId":"50413610-f723-4ae8-e35d-e108d00f4526","executionInfo":{"status":"ok","timestamp":1580910113822,"user_tz":-480,"elapsed":457827,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["NFOLDS = 5\n","BATCH_SIZE = 4\n","EPOCHS = 4\n","SEED = 9638 ## the seed of model0202_a2\n","num_warmup_steps = 100\n","lr = 3e-5\n","\n","\n","gradient_accumulation_steps = 1\n","seed_everything(SEED)\n","\n","\n","y_oof_a = np.zeros((len(train), 9))\n","test_pred_a = np.zeros((len(test), 9))\n","\n","kf = KFold(n_splits=NFOLDS, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n","    \n","\n","    print(f'fold {i+1}')\n","    gc.collect()\n","    \n","    ## loader\n","    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    net = model_list[i]\n","    net.cuda()\n","\n","\n","    valid_preds = np.zeros((len(valid_idx), 9))\n","        \n","    net.eval()\n","    for j,data in enumerate(val_loader):\n","\n","        # get the inputs\n","        input_ids, input_masks, input_segments, labels = data\n","        pred = net(input_ids = input_ids.long().cuda(),\n","                        labels = None,\n","                        attention_mask = input_masks.cuda(),\n","                        token_type_ids = input_segments.long().cuda()\n","                        )[0]\n","\n","\n","        valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n","\n","    y_oof_a[valid_idx] = valid_preds\n","    \n","    result = list()\n","\n","\n","    net.eval()\n","    with torch.no_grad():\n","        for data in test_loader:\n","            input_ids, input_masks, input_segments, labels = data\n","            y_pred = net(input_ids = input_ids.long().cuda(),\n","                                labels = None,\n","                                attention_mask = input_masks.cuda(),\n","                                token_type_ids = input_segments.long().cuda(),\n","                            )[0]\n","\n","            result.extend(y_pred.cpu().detach().numpy())\n","            \n","    test_pred_a += np.array(result)/NFOLDS\n","\n","\n","        \n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wvgp29lAO2mD","colab_type":"code","colab":{}},"source":["y_oof = np.concatenate((y_oof_q,y_oof_a), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ir_WuPWl-dB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"52add498-b542-4408-f5d2-005286ff4c17","executionInfo":{"status":"ok","timestamp":1580910245417,"user_tz":-480,"elapsed":2073,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}}},"source":["y_oof"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.93363047,  1.12548411, -2.5730741 , ..., -2.24046254,\n","         1.30352974,  3.06612873],\n","       [ 2.66859078,  1.30669618, -3.52617574, ..., -4.81498289,\n","        -0.34807563,  2.73056793],\n","       [ 2.51805305, -0.54163224, -5.48230886, ..., -1.16979015,\n","        -0.34471586,  3.33662391],\n","       ...,\n","       [ 2.04946923,  0.43975094, -5.66392279, ..., -1.76347637,\n","         0.57397175,  1.44047928],\n","       [ 2.6926918 ,  0.7509892 ,  0.23309958, ..., -2.04652977,\n","         2.81085157,  2.69586039],\n","       [ 3.02421236,  1.47668231, -2.23732352, ..., -3.88071632,\n","         3.14613461,  2.69052005]])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"7gmy0yVnQEfw","colab_type":"code","colab":{}},"source":["test_pred = np.concatenate((test_pred_q,test_pred_a), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k924n1Fqjxcw","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/y_oof_bert.pkl\",\"wb\") as f:\n","    pickle.dump(y_oof,f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jej-dPNwjxiF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRmJkLDejxmC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqPNGBnGjxgA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CLlCZ0ljxaV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltUawd93QDSU","colab_type":"code","colab":{}},"source":["test_pred.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2iGN-53O2o-","colab_type":"code","colab":{}},"source":["y_oof.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IwLNcTmho2_","colab_type":"code","colab":{}},"source":["oof_score = 0\n","for i in range(30):\n","    oof_score += np.nan_to_num(\n","            spearmanr(y_train[:, i], y_oof[:, i]).correlation / 30)   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJyK9teJQowr","colab_type":"code","outputId":"1caa228f-c6b3-46d6-b235-5adc6d98dfea","executionInfo":{"status":"ok","timestamp":1580910126266,"user_tz":-480,"elapsed":1816,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.409722898587619\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bxx6YCuK3uMO","colab_type":"code","outputId":"edc02201-80ba-42da-fb0a-6a75821bac2d","executionInfo":{"status":"ok","timestamp":1580651426926,"user_tz":-480,"elapsed":558,"user":{"displayName":"林得恩","photoUrl":"","userId":"01685505290946491737"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.4097228870494785\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"51ODmGFJcQuz","colab_type":"code","colab":{}},"source":["def f_0(x):\n","    if x <= 0.1666:\n","        x = 0.0000001\n","    if x >= 0.94:\n","        x = 0.99999999\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"04TvYLGycQsE","colab_type":"code","colab":{}},"source":["a = torch.sigmoid(torch.tensor(y_oof)).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcFcl2jEd8Mk","colab_type":"code","outputId":"fb1c2511-b958-417a-82ef-f534bc00f55e","executionInfo":{"status":"ok","timestamp":1580829559493,"user_tz":-480,"elapsed":759,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["a"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.94948409, 0.75500454, 0.07089156, ..., 0.09617533, 0.78642843,\n","        0.95547376],\n","       [0.93514762, 0.78695978, 0.02857656, ..., 0.00804216, 0.41384915,\n","        0.93880647],\n","       [0.92539776, 0.36780796, 0.00414248, ..., 0.23689292, 0.41466439,\n","        0.96566408],\n","       ...,\n","       [0.88589398, 0.60819968, 0.00345689, ..., 0.14635548, 0.63967913,\n","        0.80852886],\n","       [0.93659402, 0.6793942 , 0.55801245, ..., 0.1144035 , 0.94325941,\n","        0.93678193],\n","       [0.95365605, 0.81407094, 0.09644853, ..., 0.0202188 , 0.95875614,\n","        0.93646493]])"]},"metadata":{"tags":[]},"execution_count":289}]},{"cell_type":"code","metadata":{"id":"xg-7FQ2BcQqQ","colab_type":"code","colab":{}},"source":["a[:,13] = np.array(list(map(f_0,a[:,13])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6paym31ge3K","colab_type":"code","outputId":"9d4fdce3-dd55-4fd8-f86c-50f5d70283fc","executionInfo":{"status":"ok","timestamp":1580829584354,"user_tz":-480,"elapsed":888,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["spearmanr(y_train[:,13], a[:,13]).correlation"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.14692425170540818"]},"metadata":{"tags":[]},"execution_count":293}]},{"cell_type":"code","metadata":{"id":"KZK4lo66P8nT","colab_type":"code","outputId":"aacdd90d-692f-402b-a8ba-40153d9d3754","executionInfo":{"status":"ok","timestamp":1580829681983,"user_tz":-480,"elapsed":836,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["spearmanr(y_train[:, 13], a[:, 13]).correlation"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.14692425170540818"]},"metadata":{"tags":[]},"execution_count":294}]},{"cell_type":"code","metadata":{"id":"EPHtUiB_MBAX","colab_type":"code","colab":{}},"source":["a = postProcessing(a)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFUB0CJJMBDS","colab_type":"code","colab":{}},"source":["oof_score = 0\n","for i in range(30):\n","    oof_score += np.nan_to_num(\n","            spearmanr(y_train[:, i], a[:, i]).correlation / 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AL4OKdUPvY9u","colab_type":"code","outputId":"726fc2ce-7809-4639-d556-ae0f41f27339","executionInfo":{"status":"ok","timestamp":1580828921429,"user_tz":-480,"elapsed":437,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.4348075468555518\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Y5UbOECuoX2","colab_type":"code","outputId":"bab5c2e3-9fd5-4435-b8db-02406c68d4e1","executionInfo":{"status":"ok","timestamp":1580828756321,"user_tz":-480,"elapsed":601,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.41362842711845393\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jfLHUttiMBHL","colab_type":"code","outputId":"f63ee1cd-e573-4ee8-dbe2-e732108903b2","executionInfo":{"status":"ok","timestamp":1580828751723,"user_tz":-480,"elapsed":699,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.409722898587619\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gY71cnPfuxus","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4WUwUVMeuxy6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Un1cVZxFux3_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzZsG26Etspb","colab_type":"code","colab":{}},"source":["def postProcessing(x):\n","\n","    def f_0(x):\n","        if x <= 0.1666:\n","            x = 0.0000001\n","        if x >= 0.833:\n","            x = 0.99999999\n","        return x\n","\n","    def f_1(x):\n","        if x <= 0.1666:\n","            x = 0.00000001\n","        # if x >= 0.8333:\n","        #     x = 0.99999999\n","        return x\n","\n","    x[:,2] = np.array(list(map(f_0,x[:,2])))\n","    x[:,5] = np.array(list(map(f_0,x[:,5])))\n","    x[:,11] = np.array(list(map(f_0,x[:,11])))\n","    x[:,15] = np.array(list(map(f_0,x[:,15])))\n","\n","    x[:,8] = np.array(list(map(f_1,x[:,8])))\n","    x[:,12] = np.array(list(map(f_1,x[:,12])))\n","    x[:,14] = np.array(list(map(f_1,x[:,14])))\n","\n","    return x\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwYoRdtDtsuv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfzAsx2lts1v","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY7cG7YHtszf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQcmw56Wtsx0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxVChHaMtstL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VViu-mZKW-34","colab_type":"code","colab":{}},"source":["sample_submission.loc[:, output_categories] = test_pred\n","sample_submission.to_csv('/content/drive/My Drive/qa_submission/submission0202_2.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_znLgVDZtsNf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cqjutvq0tsLV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_6UwC5dtsIj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwlOS2F9tsEz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GDq0AsGhxEM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"appPXTg2hxG_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nm7CjrorhxML","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCmtqG7ehxPd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}