{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"RoBERTa_special_token_a.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cc2691ec32bd4906b0c1eeb8db310aa0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b80e513a4a784d0b8cc3a6292e8b68bb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_98aa236b6a3f4839b7235d1f06c8fd04","IPY_MODEL_604f600d6ed14274b7dc4586aaa9f0d8"]}},"b80e513a4a784d0b8cc3a6292e8b68bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98aa236b6a3f4839b7235d1f06c8fd04":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62e00c54edf64cb69604350bfd1fca61","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae46f79361e446ea9534705c80f2bb4f"}},"604f600d6ed14274b7dc4586aaa9f0d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_958704306f6148028aca407e408fd5c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 899k/899k [00:00&lt;00:00, 12.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e3f41f152b24f39b63fc7a455c0262f"}},"62e00c54edf64cb69604350bfd1fca61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae46f79361e446ea9534705c80f2bb4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"958704306f6148028aca407e408fd5c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e3f41f152b24f39b63fc7a455c0262f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3152f6d88fe45e9bcbf354103517f4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fed99a31aef94dfab8551cadf1a9b46c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f468a6b0a454ceaa0057d21526493bc","IPY_MODEL_99c6a9f4bbee4ce387188920050a31ed"]}},"fed99a31aef94dfab8551cadf1a9b46c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f468a6b0a454ceaa0057d21526493bc":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_407b07a58e2b49fda152aef5cd35899e","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c91ab20b6024fadb17238d36f828e4b"}},"99c6a9f4bbee4ce387188920050a31ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc4402419a1546c49b2f3641658f6b9c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 456k/456k [00:00&lt;00:00, 6.42MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87f0eade17f24c07a8202d9cf83dea63"}},"407b07a58e2b49fda152aef5cd35899e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c91ab20b6024fadb17238d36f828e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc4402419a1546c49b2f3641658f6b9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87f0eade17f24c07a8202d9cf83dea63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"434a65319c864357abea4bc3154a9351":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_79602396bdfe4390a11cea4f44716d94","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e4d01e0185a43a597e77c64b9651696","IPY_MODEL_09bbfab487f94cb38eaa7149b29e7edb"]}},"79602396bdfe4390a11cea4f44716d94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e4d01e0185a43a597e77c64b9651696":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_69e742cfa5b945a3a1c87f3ed4a7d745","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8232e91de3024eb692de0dffd5916771"}},"09bbfab487f94cb38eaa7149b29e7edb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_456c4407641e4a7da7e351940e76d262","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 524/524 [00:00&lt;00:00, 17.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81bf5e979ce94ae2aeef6455ab42ba0f"}},"69e742cfa5b945a3a1c87f3ed4a7d745":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8232e91de3024eb692de0dffd5916771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"456c4407641e4a7da7e351940e76d262":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81bf5e979ce94ae2aeef6455ab42ba0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91da7a19cfa948e0b3fffd229abd912f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_40e2c616dc374cd29801ce37687da26f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cbc6e5a94fb34a298f2cdb28042c4234","IPY_MODEL_ed68604266dc47ddbcf12d620b3da316"]}},"40e2c616dc374cd29801ce37687da26f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cbc6e5a94fb34a298f2cdb28042c4234":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_00e7138dcdc7445ab3508487d5b57aab","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e959646d9474c1e80d1916badd5b5ee"}},"ed68604266dc47ddbcf12d620b3da316":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_39b14b344d0548b8b3adbe4281522d0a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 501M/501M [00:10&lt;00:00, 49.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9319222f0d5f4ffdbd1456aaa03dc168"}},"00e7138dcdc7445ab3508487d5b57aab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4e959646d9474c1e80d1916badd5b5ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39b14b344d0548b8b3adbe4281522d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9319222f0d5f4ffdbd1456aaa03dc168":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"KD6JKyGoW-3a","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('..'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz_vXPEMHfAL","colab_type":"code","outputId":"8626beb2-9c48-4660-84bd-903a50b28378","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1581220907486,"user_tz":-480,"elapsed":4401,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Feb  9 04:01:44 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ZhO3xxuXtwR","colab_type":"code","outputId":"d65e6c3b-e85d-4c9b-c205-c754116c7116","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1581220926237,"user_tz":-480,"elapsed":17612,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uq49afG7bPLx","colab_type":"code","outputId":"a0e9a89e-a872-4bb6-d974-0b90e5c2598d","colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"status":"ok","timestamp":1581220934503,"user_tz":-480,"elapsed":9193,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\u001b[K     |████████████████████████████████| 481kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 6.7MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 20.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 29.0MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=85b1f1e3e5bb0ec8e54c9e6999bb54b8c3678e28d656aa69b25c628339799541\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"","_uuid":"","id":"QHc6btamW-3h","colab_type":"code","outputId":"523106e9-21f3-4e1a-98af-56bec7d8afb8","colab":{"base_uri":"https://localhost:8080/","height":63},"executionInfo":{"status":"ok","timestamp":1581220939075,"user_tz":-480,"elapsed":11640,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import random\n","import pickle\n","import tensorflow.keras.backend as K\n","import gc\n","import time\n","import re\n","import os\n","import torch\n","from scipy.stats import spearmanr\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import KFold,StratifiedKFold\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","from transformers import AdamW,BertForSequenceClassification\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SlYdOWB3W-3j","colab_type":"code","colab":{}},"source":["sample_submission = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/sample_submission.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/test.csv\")\n","train = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/train.csv\")\n","\n","MAX_SEQUENCE_LENGTH = 512"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIqdsDMrW-3l","colab_type":"code","outputId":"1d561d25-cefa-4127-8f14-3e5205c84782","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1581220940674,"user_tz":-480,"elapsed":12792,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["print('train shape =', train.shape)\n","print('test shape =', test.shape)\n","\n","output_categories = list(train.columns[11:])\n","input_categories = list(train.columns[[1,2,5]])\n","print('\\noutput categories:\\n\\t', output_categories)\n","print('\\ninput categories:\\n\\t', input_categories)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["train shape = (6079, 41)\n","test shape = (476, 11)\n","\n","output categories:\n","\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n","\n","input categories:\n","\t ['question_title', 'question_body', 'answer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kUxaDX5l2jaT","colab_type":"code","outputId":"ea51aefe-440d-40cc-c73e-23c3740e0626","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1581220940675,"user_tz":-480,"elapsed":10976,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["len(output_categories)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"J91XPg5D2l-G","colab_type":"code","outputId":"d754ae45-4401-4d87-bb66-c7a2088c54ae","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1581220940675,"user_tz":-480,"elapsed":10162,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["output_categories[21:]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['answer_helpful',\n"," 'answer_level_of_information',\n"," 'answer_plausible',\n"," 'answer_relevance',\n"," 'answer_satisfaction',\n"," 'answer_type_instructions',\n"," 'answer_type_procedure',\n"," 'answer_type_reason_explanation',\n"," 'answer_well_written']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Fw-o2_9SW-3n","colab_type":"code","colab":{}},"source":["def _get_masks(tokens, max_seq_length):\n","    \"\"\"Mask for padding\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","\n","def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == '<SEP>':\n","            if first_sep:\n","                first_sep = False \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [1] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input(title, question, answer, max_sequence_length, \n","                t_max_len=30, q_max_len=233, a_max_len=234):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+15) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+15 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+15)))\n","        \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","        if a_len > a_new_len:\n","            ind1 = floor(a_new_len/2)\n","            ind2 = ceil(a_new_len/2)\n","            a = a[:ind1]+a[-ind2:]\n","        else:\n","            a = a[:a_new_len]\n","    \n","    return t, q, a\n","\n","def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    \n","    stoken = ['<s>','<a1>','<a2>','<a3>','<a4>','<a5>','<a6>','<a7>','<a8>','<a9>'] + title + ['</s>','</s>'] + question + ['</s>','</s>'] + answer + ['</s>']\n","\n","    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n","    input_masks = _get_masks(stoken, max_sequence_length)\n","    input_segments = _get_segments(stoken, max_sequence_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        t, q, a = _trim_input(t, q, a, max_sequence_length)\n","\n","        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n","        input_ids.append(ids)\n","        input_masks.append(masks)\n","        input_segments.append(segments)\n","        \n","    return [np.asarray(input_ids, dtype=np.int32), \n","            np.asarray(input_masks, dtype=np.int32), \n","            np.asarray(input_segments, dtype=np.int32)]\n","\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcJFuVXDW-3p","colab_type":"code","colab":{}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"323A8fOJW-3r","colab_type":"code","colab":{}},"source":["class TextDataset(torch.utils.data.TensorDataset):\n","\n","    def __init__(self, x_train, idxs, targets=None):\n","        self.input_ids = x_train[0][idxs]\n","        self.input_masks = x_train[1][idxs]\n","        self.input_segments = x_train[2][idxs]\n","        self.targets = targets[idxs] if targets is not None else np.zeros((x_train[0].shape[0], 30))\n","\n","    def __getitem__(self, idx):\n","#         x_train = self.x_train[idx]\n","        input_ids =  self.input_ids[idx]\n","        input_masks = self.input_masks[idx]\n","        input_segments = self.input_segments[idx]\n","\n","        target = self.targets[idx]\n","\n","        return input_ids, input_masks, input_segments, target\n","\n","    def __len__(self):\n","        return len(self.input_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ1oU5n_W-3t","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer,BertConfig,get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHPC2AE4CLuR","colab_type":"code","colab":{}},"source":["from transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, get_cosine_with_hard_restarts_schedule_with_warmup"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TXqSLKNW-3v","colab_type":"code","outputId":"bd1493eb-640e-4556-f1a8-2f4ffb32c521","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["cc2691ec32bd4906b0c1eeb8db310aa0","b80e513a4a784d0b8cc3a6292e8b68bb","98aa236b6a3f4839b7235d1f06c8fd04","604f600d6ed14274b7dc4586aaa9f0d8","62e00c54edf64cb69604350bfd1fca61","ae46f79361e446ea9534705c80f2bb4f","958704306f6148028aca407e408fd5c2","5e3f41f152b24f39b63fc7a455c0262f","f3152f6d88fe45e9bcbf354103517f4f","fed99a31aef94dfab8551cadf1a9b46c","9f468a6b0a454ceaa0057d21526493bc","99c6a9f4bbee4ce387188920050a31ed","407b07a58e2b49fda152aef5cd35899e","0c91ab20b6024fadb17238d36f828e4b","bc4402419a1546c49b2f3641658f6b9c","87f0eade17f24c07a8202d9cf83dea63"]},"executionInfo":{"status":"ok","timestamp":1581220941024,"user_tz":-480,"elapsed":6015,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["pretrained_weights = 'roberta-base'\n","tokenizer = RobertaTokenizer.from_pretrained(pretrained_weights)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc2691ec32bd4906b0c1eeb8db310aa0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=898823, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3152f6d88fe45e9bcbf354103517f4f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r9tcDBLG13Hg","colab_type":"code","outputId":"3fa17962-07bb-49b0-d61c-10e2f59d327b","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1581220941024,"user_tz":-480,"elapsed":3902,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["special_tokens =['<a'+str(i)+'>' for i in range(1,10)]\n","special_tokens_dict = {\"additional_special_tokens\":special_tokens}\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","print('We have added', num_added_toks, 'tokens')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["We have added 9 tokens\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RFZcbly46yTe","colab_type":"code","colab":{}},"source":["output_categories_a = output_categories[21:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIDwzqeAFlOo","colab_type":"code","outputId":"2c88d47c-917a-4ffd-c4b3-9acad9582754","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1581220941026,"user_tz":-480,"elapsed":3441,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["output_categories_a"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['answer_helpful',\n"," 'answer_level_of_information',\n"," 'answer_plausible',\n"," 'answer_relevance',\n"," 'answer_satisfaction',\n"," 'answer_type_instructions',\n"," 'answer_type_procedure',\n"," 'answer_type_reason_explanation',\n"," 'answer_well_written']"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"UCp7_1H-W-3x","colab_type":"code","outputId":"92ed43cf-2e03-4435-8ca8-12f9918afc23","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1581220959042,"user_tz":-480,"elapsed":20931,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","y_train = compute_output_arrays(train, output_categories_a)\n","x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["6079it [00:16, 377.13it/s]\n","476it [00:01, 377.10it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4DDifo4R5SdK","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import RobertaConfig, RobertaModel, RobertaForSequenceClassification, BertPreTrainedModel\n","\n","\n","ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = {\n","    \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin\",\n","    \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin\",\n","    \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin\",\n","    \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin\",\n","    \"roberta-base-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin\",\n","    \"roberta-large-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin\",\n","}\n","\n","class BertHead(nn.Module):\n","    def __init__(self, dp, feat_size):\n","        super(BertHead, self).__init__()\n","        self.dropout = nn.Dropout(dp)\n","        self.linear = nn.Linear(feat_size, 1)\n","    def forward(self, x):\n","        x = self.dropout(x)\n","        return self.linear(x)\n","\n","\n","class CustomizedRoberta(BertPreTrainedModel):\n","    config_class = RobertaConfig\n","    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n","    base_model_prefix = \"roberta\"\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        self.config = config\n","        self.config.output_hidden_states=True\n","        self.roberta = RobertaModel(self.config)\n","        self.tqa_heads = nn.ModuleList([BertHead(0.1, self.config.hidden_size) for _ in range(self.config.num_labels)])\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","        tq_outputs = []\n","        for ix in torch.arange(self.config.num_labels):\n","            # retreve ith special token to do the task!\n","            feat = outputs[2][-1][:, ix+1, :]\n","            out = self.tqa_heads[ix](feat)\n","            tq_outputs += [out.view(-1, 1)]\n","        tq_outputs = torch.cat(tq_outputs, 1)\n","\n","        outputs = (tq_outputs,) + outputs[2:]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITMu2nKrHqXL","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","class callback:\n","    def __init__(self):\n","        self.score = list()\n","        self.model = list()\n","        self.data = list()\n","    \n","    def put(self, model,data, score):\n","        self.score.append(score)\n","        self.model.append(model)\n","        self.data.append(data)\n","\n","    def get_model(self):\n","        ind = np.argmin(self.score)\n","        return self.model[ind]\n","    def get_data(self):\n","        ind = np.argmin(self.score)\n","        return self.data[ind]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jYqd5JPW-33","colab_type":"code","outputId":"35e75a1d-51da-44e6-99c2-2d685a7741cd","colab":{"base_uri":"https://localhost:8080/","height":540,"referenced_widgets":["434a65319c864357abea4bc3154a9351","79602396bdfe4390a11cea4f44716d94","6e4d01e0185a43a597e77c64b9651696","09bbfab487f94cb38eaa7149b29e7edb","69e742cfa5b945a3a1c87f3ed4a7d745","8232e91de3024eb692de0dffd5916771","456c4407641e4a7da7e351940e76d262","81bf5e979ce94ae2aeef6455ab42ba0f","91da7a19cfa948e0b3fffd229abd912f","40e2c616dc374cd29801ce37687da26f","cbc6e5a94fb34a298f2cdb28042c4234","ed68604266dc47ddbcf12d620b3da316","00e7138dcdc7445ab3508487d5b57aab","4e959646d9474c1e80d1916badd5b5ee","39b14b344d0548b8b3adbe4281522d0a","9319222f0d5f4ffdbd1456aaa03dc168"]},"executionInfo":{"status":"ok","timestamp":1581228189034,"user_tz":-480,"elapsed":5374796,"user":{"displayName":"陳芃璇","photoUrl":"","userId":"10465237809525521958"}}},"source":["NFOLDS = 5\n","BATCH_SIZE = 4\n","EPOCHS = 4\n","SEED = 4845\n","num_warmup_steps = 100\n","lr = 3e-5\n","\n","\n","gradient_accumulation_steps = 1\n","seed_everything(SEED)\n","\n","model_list = list()\n","\n","\n","y_oof = np.zeros((len(train), 9))\n","test_pred = np.zeros((len(test), 9))\n","\n","\n","y_oof = np.zeros((len(train), 9))\n","test_pred = np.zeros((len(test), 9))\n","\n","kf = KFold(n_splits=NFOLDS, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n","    \n","    \n","    print(f'fold {i+1}')\n","    gc.collect()\n","    \n","    ## loader\n","    train_loader = torch.utils.data.DataLoader(TextDataset(x_train, train_idx, y_train),batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    t_total = len(train_loader)//gradient_accumulation_steps*EPOCHS\n","\n","    roberta_config = RobertaConfig.from_pretrained(pretrained_weights) \n","    roberta_config.num_labels = 9\n","    net = CustomizedRoberta.from_pretrained(pretrained_weights, config=roberta_config)\n","    net.resize_token_embeddings(len(tokenizer))\n","    net.cuda()\n","    \n","    loss_fn = torch.nn.BCEWithLogitsLoss()\n","    optimizer = AdamW(net.parameters(), lr = lr)\n","    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler\n","\n","    cb = callback()\n","\n","\n","    for epoch in range(EPOCHS):  \n","\n","        start_time = time.time()\n","        avg_loss = 0.0\n","        net.train()\n","\n","        for step, data in enumerate(train_loader):\n","\n","            # get the inputs\n","            input_ids, input_masks, input_segments, labels = data\n","\n","\n","            pred = net(input_ids = input_ids.long().cuda(),\n","                             labels = None,\n","                             attention_mask = input_masks.cuda()\n","                            )[0]\n","            \n","            \n","            loss = loss_fn(pred, labels.cuda())\n","        \n","            avg_loss += loss.item()\n","            loss = loss / gradient_accumulation_steps\n","            loss.backward()\n","\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","\n","                # Calling the step function on an Optimizer makes an update to its parameters\n","                optimizer.step()\n","                scheduler.step()\n","                optimizer.zero_grad()\n","                \n","                \n","        avg_val_loss = 0.0\n","\n","        valid_preds = np.zeros((len(valid_idx), 9))\n","        true_label = np.zeros((len(valid_idx), 9))\n","        \n","\n","        net.eval()\n","        for j,data in enumerate(val_loader):\n","\n","            # get the inputs\n","            input_ids, input_masks, input_segments, labels = data\n","            pred = net(input_ids = input_ids.long().cuda(),\n","                             labels = None,\n","                             attention_mask = input_masks.cuda()\n","                            )[0]\n","\n","            loss_val = loss_fn(pred, labels.cuda())\n","            avg_val_loss += loss_val.item()\n","\n","\n","            valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n","            true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels\n","\n","\n","        elapsed_time = time.time() - start_time \n","\n","        score = 0\n","        for i in range(9):\n","          s = np.nan_to_num(\n","                    spearmanr(true_label[:, i], valid_preds[:, i]).correlation / 9)\n","          score += s\n","\n","        \n","\n","        print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f}\\t spearmanr={:.4f}\\t time={:.2f}s'.format(epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader),score, elapsed_time))\n","\n","        cb.put(net,valid_preds,avg_val_loss/len(val_loader))\n","\n","\n","\n","    model_list.append(cb.get_model())\n","    y_oof[valid_idx] = cb.get_data()\n","        \n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["fold 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"434a65319c864357abea4bc3154a9351","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=524, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91da7a19cfa948e0b3fffd229abd912f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=501200538, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 1/4 \t loss=0.3900\t val_loss=0.3683\t spearmanr=0.2862\t time=359.70s\n","Epoch 2/4 \t loss=0.3637\t val_loss=0.3622\t spearmanr=0.3408\t time=359.59s\n","Epoch 3/4 \t loss=0.3469\t val_loss=0.3640\t spearmanr=0.3556\t time=359.64s\n","Epoch 4/4 \t loss=0.3338\t val_loss=0.3667\t spearmanr=0.3532\t time=359.42s\n","fold 2\n","Epoch 1/4 \t loss=0.3872\t val_loss=0.3773\t spearmanr=0.2954\t time=359.30s\n","Epoch 2/4 \t loss=0.3605\t val_loss=0.3702\t spearmanr=0.3206\t time=360.21s\n","Epoch 3/4 \t loss=0.3427\t val_loss=0.3696\t spearmanr=0.3476\t time=358.53s\n","Epoch 4/4 \t loss=0.3281\t val_loss=0.3731\t spearmanr=0.3469\t time=358.67s\n","fold 3\n","Epoch 1/4 \t loss=0.3903\t val_loss=0.3671\t spearmanr=0.2889\t time=357.07s\n","Epoch 2/4 \t loss=0.3613\t val_loss=0.3644\t spearmanr=0.3323\t time=359.15s\n","Epoch 3/4 \t loss=0.3435\t val_loss=0.3644\t spearmanr=0.3501\t time=358.04s\n","Epoch 4/4 \t loss=0.3302\t val_loss=0.3687\t spearmanr=0.3452\t time=358.01s\n","fold 4\n","Epoch 1/4 \t loss=0.3880\t val_loss=0.3677\t spearmanr=0.2994\t time=358.84s\n","Epoch 2/4 \t loss=0.3608\t val_loss=0.3620\t spearmanr=0.3452\t time=358.44s\n","Epoch 3/4 \t loss=0.3432\t val_loss=0.3627\t spearmanr=0.3607\t time=360.38s\n","Epoch 4/4 \t loss=0.3290\t val_loss=0.3661\t spearmanr=0.3559\t time=358.78s\n","fold 5\n","Epoch 1/4 \t loss=0.3914\t val_loss=0.3585\t spearmanr=0.2992\t time=359.66s\n","Epoch 2/4 \t loss=0.3644\t val_loss=0.3550\t spearmanr=0.3356\t time=359.88s\n","Epoch 3/4 \t loss=0.3479\t val_loss=0.3537\t spearmanr=0.3524\t time=361.14s\n","Epoch 4/4 \t loss=0.3346\t val_loss=0.3555\t spearmanr=0.3564\t time=360.07s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QDCONI_-E4AS","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/model0209_roberta_special_token_a.pkl\",\"wb\") as f:\n","    pickle.dump(model_list,f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjgfigGaB1oG","colab_type":"code","colab":{}},"source":[" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NjBX7xmDB1rF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lb-bW-trB10Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vWYS2xohfu4i","colab_type":"code","colab":{}},"source":["oof_score = 0\n","for i in range(30):\n","    oof_score += np.nan_to_num(\n","            spearmanr(y_train[:, i], y_oof[:, i]).correlation / 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxx6YCuK3uMO","colab_type":"code","outputId":"145270f3-c89d-46f2-d589-d9ac6ab6209e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.3103592024675693\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VViu-mZKW-34","colab_type":"code","colab":{}},"source":["sample_submission.loc[:, output_categories] = test_pred\n","sample_submission.to_csv('/content/drive/My Drive/qa_submission/submission0129.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfbvM2hrtVwY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EsV2jETOtVzn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxq_DrlrtV22","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}