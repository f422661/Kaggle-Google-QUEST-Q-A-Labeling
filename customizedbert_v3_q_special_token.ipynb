{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "KD6JKyGoW-3a"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('..'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TMIL5TP-cTWG"
   },
   "outputs": [],
   "source": [
    "## cv 0.41542 lb 0.405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5050,
     "status": "ok",
     "timestamp": 1581175754115,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "Gz_vXPEMHfAL",
    "outputId": "49d940a3-85c4-42fc-f1b4-1d3ed375f6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb  8 15:29:10 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24739,
     "status": "ok",
     "timestamp": 1581175774386,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "8ZhO3xxuXtwR",
    "outputId": "051a0ab1-8320-4300-cc3e-add3c6326387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10738,
     "status": "ok",
     "timestamp": 1581175786380,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "Uq49afG7bPLx",
    "outputId": "c831f78d-37a9-4ca1-8ee3-27519aa7b2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
      "\r",
      "\u001b[K     |▊                               | 10kB 28.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 30kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 40kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 61kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 71kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 81kB 3.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 92kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 102kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 112kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 122kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 133kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 143kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 153kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 163kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 174kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 184kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 194kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 204kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 215kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 225kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 235kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 245kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 256kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 266kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 276kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 286kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 296kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 307kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 317kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 327kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 337kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 348kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 358kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 368kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 378kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 389kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 399kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 409kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 419kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 430kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 440kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 450kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 460kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 471kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 481kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 75.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 45.3MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.0.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 44.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=7f52328c92ce39e50dc0dd90f5ed67dca9beeae777c17d2b6dde571f29022def\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "",
    "_uuid": "",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14819,
     "status": "ok",
     "timestamp": 1581175790902,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "QHc6btamW-3h",
    "outputId": "b04871bd-eba7-4163-e6f9-a6e06f17d773"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import AdamW,BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlYdOWB3W-3j"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/sample_submission.csv\")\n",
    "test = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/test.csv\")\n",
    "train = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/train.csv\")\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13051,
     "status": "ok",
     "timestamp": 1581175791529,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "lIqdsDMrW-3l",
    "outputId": "6c09471d-bb1a-4903-cee4-75d7dab563cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (6079, 41)\n",
      "test shape = (476, 11)\n",
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer']\n"
     ]
    }
   ],
   "source": [
    "print('train shape =', train.shape)\n",
    "print('test shape =', test.shape)\n",
    "\n",
    "output_categories = list(train.columns[11:])\n",
    "input_categories = list(train.columns[[1,2,5]])\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10944,
     "status": "ok",
     "timestamp": 1581175791530,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "kUxaDX5l2jaT",
    "outputId": "e8e36874-4309-4bd7-dde3-96aac1ff776f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10732,
     "status": "ok",
     "timestamp": 1581175791530,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "J91XPg5D2l-G",
    "outputId": "e6353b01-c874-4073-835c-8cf4169320dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_categories[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fw-o2_9SW-3n"
   },
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input_q(title, question,max_sequence_length, \n",
    "                t_max_len=50, q_max_len=438):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "\n",
    "    if (t_len+q_len+24) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            q_max_len = q_max_len + (t_max_len - t_len)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "\n",
    "        q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+ q_new_len+24 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "            \n",
    "        if t_len > t_new_len:\n",
    "            ind1 = floor(t_new_len/2)\n",
    "            ind2 = ceil(t_new_len/2)\n",
    "            t = t[:ind1]+t[-ind2:]\n",
    "        else:\n",
    "            t = t[:t_new_len]\n",
    "\n",
    "        if q_len > q_new_len:\n",
    "            ind1 = floor(q_new_len/2)\n",
    "            ind2 = ceil(q_new_len/2)\n",
    "            q = q[:ind1]+q[-ind2:]\n",
    "        else:\n",
    "            q = q[:q_new_len]\n",
    "\n",
    "    \n",
    "    return t, q\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\",\"[q1]\",\"[q2]\",\"[q3]\",\"[q4]\",\"[q5]\",\"[q6]\",\"[q7]\",\"[q8]\",\"[q9]\",\"[q10]\",\"[q11]\",\"[q12]\",\"[q13]\",\"[q14]\",\"[q15]\",\"[q16]\",\"[q17]\",\"[q18]\",\"[q19]\",\"[q20]\",\"[q21]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q = _trim_input_q(t, q, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcJFuVXDW-3p"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "323A8fOJW-3r"
   },
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.TensorDataset):\n",
    "\n",
    "    def __init__(self, x_train, idxs, targets=None):\n",
    "        self.input_ids = x_train[0][idxs]\n",
    "        self.input_masks = x_train[1][idxs]\n",
    "        self.input_segments = x_train[2][idxs]\n",
    "        self.targets = targets[idxs] if targets is not None else np.zeros((x_train[0].shape[0], 30))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         x_train = self.x_train[idx]\n",
    "        input_ids =  self.input_ids[idx]\n",
    "        input_masks = self.input_masks[idx]\n",
    "        input_segments = self.input_segments[idx]\n",
    "\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        return input_ids, input_masks, input_segments, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ1oU5n_W-3t"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertConfig,get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup,BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4daa7af6fc85461cbb6cf442e5302bd4",
      "67f804dbd06346af84527e6f7f0815ed",
      "97a5eb37926d4574a5a854ef1525845c",
      "6063a5482a4a4aca9751a0539d378826",
      "d7020148654d48eab66e9ee6eeb0c053",
      "06995b0f6de4472585d340ec742e22f1",
      "74c50b8e05a94b19a740bc916f2c179f",
      "7f235bdc3ce6456f827621fd7ae45346"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9505,
     "status": "ok",
     "timestamp": 1581175794111,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "4TXqSLKNW-3v",
    "outputId": "15427898-e9a6-4af8-e699-704606a39660"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4daa7af6fc85461cbb6cf442e5302bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6634,
     "status": "ok",
     "timestamp": 1581175794112,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "e1YjHFU5PtLg",
    "outputId": "fb3e5963-7644-4212-beb3-767247373381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 21 tokens\n"
     ]
    }
   ],
   "source": [
    "special_tokens =['[q'+str(i)+']' for i in range(1,22)]\n",
    "special_tokens_dict = {\"additional_special_tokens\":special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6482,
     "status": "ok",
     "timestamp": 1581175794113,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "RFZcbly46yTe",
    "outputId": "664a2746-839e-48a3-a913-22c0ce581f71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written',\n",
       " 'answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuDlWLg060ko"
   },
   "outputs": [],
   "source": [
    "output_categories_q = output_categories[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5701,
     "status": "ok",
     "timestamp": 1581175794113,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "HIjNZZtr64Iw",
    "outputId": "5d5f9468-e82c-4636-8356-220f37da083c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_categories_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26281,
     "status": "ok",
     "timestamp": 1581175816984,
     "user": {
      "displayName": "陳芃璇",
      "photoUrl": "",
      "userId": "10465237809525521958"
     },
     "user_tz": -480
    },
    "id": "UCp7_1H-W-3x",
    "outputId": "7fda1e3a-0618-42fe-b61a-1dd9d2b74f97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6079it [00:20, 297.99it/s]\n",
      "476it [00:01, 302.53it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "y_train = compute_output_arrays(train, output_categories_q)\n",
    "x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKlp16oXW-31"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from transformers import BertPreTrainedModel,BertModel\n",
    "\n",
    "class BertHead(nn.Module):\n",
    "    def __init__(self, dp, feat_size):\n",
    "        super(BertHead, self).__init__()\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        self.linear = nn.Linear(feat_size, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "class CustomizedBert(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(CustomizedBert, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.config.output_hidden_states=True\n",
    "        self.bert = BertModel(self.config)\n",
    "        self.tqa_heads = nn.ModuleList([BertHead(0.1, self.config.hidden_size) for _ in range(self.config.num_labels)])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "\n",
    "        tq_outputs = []\n",
    "        for ix in torch.arange(self.config.num_labels):\n",
    "            # retreve ith special token to do the task!\n",
    "            feat = outputs[2][-1][:, ix+1, :]\n",
    "            out = self.tqa_heads[ix](feat)\n",
    "            tq_outputs += [out.view(-1, 1)]\n",
    "        tq_outputs = torch.cat(tq_outputs, 1)\n",
    "\n",
    "        outputs = (tq_outputs,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITMu2nKrHqXL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class callback:\n",
    "    def __init__(self):\n",
    "        self.score = list()\n",
    "        self.model = list()\n",
    "        self.data = list()\n",
    "    \n",
    "    def put(self, model,data, score):\n",
    "        self.score.append(score)\n",
    "        self.model.append(model)\n",
    "        self.data.append(data)\n",
    "\n",
    "    def get_model(self):\n",
    "        ind = np.argmin(self.score)\n",
    "        return self.model[ind]\n",
    "    def get_data(self):\n",
    "        ind = np.argmin(self.score)\n",
    "        return self.data[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234,
     "referenced_widgets": [
      "e9e6ceb8f1174061819d33dc0a123a07",
      "6f630f60ef074ae281c9a3b63eca9bba",
      "a503a1f1e7784f6bb0a3c38354193e8f",
      "9bd4a5b41a3942cd874ed08967e9d256",
      "ad1c5faa41694d40946e3f2fe5d3c6a1",
      "37585d76298c4756ba1b05e103b46137",
      "33784bdf13464bc8beb1b605e8304614",
      "b3020e1a1d234b47bc2e626cf7346774",
      "8424c1325f7847ad9ec91f2b8e6930f1",
      "b47f60d2de3f4bc2a4ad87d724cb5692",
      "41d50d4a98b44cd08ba5b7614a9986ed",
      "8f841e8eff22436fae7f1cd6c8e27c32",
      "737888229ae94cbfb27e0b5d513dde41",
      "d723e15886774886bca71d08d8023d04",
      "2e95656870b2484cb3349386e28f0117",
      "b9e8d5d6ad65445f98b2a35449d8062c"
     ]
    },
    "colab_type": "code",
    "id": "0jYqd5JPW-33",
    "outputId": "9b9ad7d5-fd80-4845-f698-bd3fe96f9d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e6ceb8f1174061819d33dc0a123a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8424c1325f7847ad9ec91f2b8e6930f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4 \t loss=0.3999\t val_loss=0.3703\t spearmanr=0.4284\t time=339.49s\n",
      "Epoch 2/4 \t loss=0.3594\t val_loss=0.3636\t spearmanr=0.4437\t time=338.99s\n",
      "Epoch 3/4 \t loss=0.3424\t val_loss=0.3633\t spearmanr=0.4477\t time=339.15s\n",
      "Epoch 4/4 \t loss=0.3307\t val_loss=0.3659\t spearmanr=0.4468\t time=338.98s\n",
      "fold 2\n",
      "Epoch 1/4 \t loss=0.3972\t val_loss=0.3743\t spearmanr=0.4053\t time=338.90s\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 4\n",
    "SEED = 2488\n",
    "num_warmup_steps = 100\n",
    "lr = 3e-5\n",
    "\n",
    "\n",
    "gradient_accumulation_steps = 1\n",
    "seed_everything(SEED)\n",
    "\n",
    "model_list = list()\n",
    "\n",
    "\n",
    "y_oof = np.zeros((len(train), 21))\n",
    "test_pred = np.zeros((len(test), 21))\n",
    "\n",
    "\n",
    "y_oof = np.zeros((len(train), 21))\n",
    "test_pred = np.zeros((len(test), 21))\n",
    "\n",
    "kf = KFold(n_splits=NFOLDS, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n",
    "    \n",
    "    \n",
    "    print(f'fold {i+1}')\n",
    "    gc.collect()\n",
    "    \n",
    "    ## loader\n",
    "    train_loader = torch.utils.data.DataLoader(TextDataset(x_train, train_idx, y_train),batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "\n",
    "    t_total = len(train_loader)//gradient_accumulation_steps*EPOCHS\n",
    "\n",
    "    bert_config = BertConfig.from_pretrained(pretrained_weights) \n",
    "    bert_config.num_labels = 21\n",
    "    net = CustomizedBert.from_pretrained(pretrained_weights, config=bert_config)\n",
    "    net.resize_token_embeddings(len(tokenizer))\n",
    "    net.cuda()\n",
    "    \n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = AdamW(net.parameters(), lr = lr)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler\n",
    "\n",
    "    cb = callback()\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):  \n",
    "\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        avg_loss = 0.0\n",
    "        net.train()\n",
    "\n",
    "\n",
    "        for step, data in enumerate(train_loader):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids, input_masks, input_segments, labels = data\n",
    "\n",
    "\n",
    "            pred = net(input_ids = input_ids.long().cuda(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks.cuda(),\n",
    "                             token_type_ids = input_segments.long().cuda()\n",
    "                            )[0]\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(pred, labels.cuda())\n",
    "        \n",
    "            avg_loss += loss.item()\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "\n",
    "                # Calling the step function on an Optimizer makes an update to its parameters\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "        avg_val_loss = 0.0\n",
    "\n",
    "        valid_preds = np.zeros((len(valid_idx), 21))\n",
    "        true_label = np.zeros((len(valid_idx), 21))\n",
    "        \n",
    "\n",
    "        net.eval()\n",
    "        for j,data in enumerate(val_loader):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids, input_masks, input_segments, labels = data\n",
    "            pred = net(input_ids = input_ids.long().cuda(),\n",
    "                             labels = None,\n",
    "                             attention_mask = input_masks.cuda(),\n",
    "                             token_type_ids = input_segments.long().cuda()\n",
    "                            )[0]\n",
    "\n",
    "            loss_val = loss_fn(pred, labels.cuda())\n",
    "            avg_val_loss += loss_val.item()\n",
    "\n",
    "\n",
    "            valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n",
    "            true_label[j * BATCH_SIZE:(j+1) * BATCH_SIZE]  = labels\n",
    "\n",
    "\n",
    "        elapsed_time = time.time() - start_time \n",
    "\n",
    "        score = 0\n",
    "        for i in range(21):\n",
    "          s = np.nan_to_num(\n",
    "                    spearmanr(true_label[:, i], valid_preds[:, i]).correlation / 21)\n",
    "          score += s\n",
    "\n",
    "        \n",
    "\n",
    "        print('Epoch {}/{} \\t loss={:.4f}\\t val_loss={:.4f}\\t spearmanr={:.4f}\\t time={:.2f}s'.format(epoch+1, EPOCHS, avg_loss/len(train_loader),avg_val_loss/len(val_loader),score, elapsed_time))\n",
    "\n",
    "        cb.put(net,valid_preds,avg_val_loss/len(val_loader))\n",
    "\n",
    "\n",
    "\n",
    "    model_list.append(cb.get_model())\n",
    "    y_oof[valid_idx] = cb.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDCONI_-E4AS"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/My Drive/qa_model/model0208_special_token_q.pkl\",\"wb\") as f:\n",
    "    pickle.dump(model_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWYS2xohfu4i"
   },
   "outputs": [],
   "source": [
    "oof_score = 0\n",
    "for i in range(30):\n",
    "    oof_score += np.nan_to_num(\n",
    "            spearmanr(y_train[:, i], y_oof[:, i]).correlation / 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bxx6YCuK3uMO",
    "outputId": "145270f3-c89d-46f2-d589-d9ac6ab6209e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of folds score = {} 0.3103592024675693\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of folds score = {}\",oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VViu-mZKW-34"
   },
   "outputs": [],
   "source": [
    "sample_submission.loc[:, output_categories] = test_pred\n",
    "sample_submission.to_csv('/content/drive/My Drive/qa_submission/submission0129.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfbvM2hrtVwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsV2jETOtVzn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wxq_DrlrtV22"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54btDlYKtV7j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neFkUDqytV-m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXuxQAKptV6D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tW8fLMuBW-36",
    "outputId": "9977d327-d095-4323-8a55-17493e2d16df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI4DwGIphUSr"
   },
   "outputs": [],
   "source": [
    "net = CustomizedBert.from_pretrained(pretrained_weights, config=bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iDI70vaCgVri",
    "outputId": "4c146022-dd6d-419c-f88e-9ba775d5cf75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = net(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Iml46F4riDHM",
    "outputId": "f8a343d8-0eb8-4e08-f1b6-6fd1a0f41326"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hLlbo3UkiEjU",
    "outputId": "e9f166ca-8c45-4370-f15c-b79b28254849"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][-1][:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "R1LjrOihiMNr",
    "outputId": "645c789e-3f64-4072-88ca-3c731dce60ad"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f9c260299c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties and _CudaDeviceProperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mDoes\u001b[0m \u001b[0mnothing\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    192\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:50"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95bXQm-tRDZs"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtGD1poLR6xy"
   },
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xdJaYAYSEH3"
   },
   "outputs": [],
   "source": [
    "def hard_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Computes element-wise hard sigmoid of x.\n",
    "    See e.g. https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/sigm.py#L279\n",
    "    \"\"\"\n",
    "    x = (0.2 * x) + 0.5\n",
    "    x = torch.clamp(x, 0.000001, 0.999999)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rGXrUWYn-3SG",
    "outputId": "96e2c8ef-f78c-48ad-8b30-cb5fe6e9029b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7000)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_sigmoid(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dGE-B67B-8NT"
   },
   "outputs": [],
   "source": [
    "hard_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrw-Bmdc-7hJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "customizedbert_v3_q_special_token.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06995b0f6de4472585d340ec742e22f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e95656870b2484cb3349386e28f0117": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33784bdf13464bc8beb1b605e8304614": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37585d76298c4756ba1b05e103b46137": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41d50d4a98b44cd08ba5b7614a9986ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d723e15886774886bca71d08d8023d04",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_737888229ae94cbfb27e0b5d513dde41",
      "value": 440473133
     }
    },
    "4daa7af6fc85461cbb6cf442e5302bd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97a5eb37926d4574a5a854ef1525845c",
       "IPY_MODEL_6063a5482a4a4aca9751a0539d378826"
      ],
      "layout": "IPY_MODEL_67f804dbd06346af84527e6f7f0815ed"
     }
    },
    "6063a5482a4a4aca9751a0539d378826": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f235bdc3ce6456f827621fd7ae45346",
      "placeholder": "​",
      "style": "IPY_MODEL_74c50b8e05a94b19a740bc916f2c179f",
      "value": "100% 232k/232k [00:00&lt;00:00, 427kB/s]"
     }
    },
    "67f804dbd06346af84527e6f7f0815ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f630f60ef074ae281c9a3b63eca9bba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "737888229ae94cbfb27e0b5d513dde41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "74c50b8e05a94b19a740bc916f2c179f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f235bdc3ce6456f827621fd7ae45346": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8424c1325f7847ad9ec91f2b8e6930f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41d50d4a98b44cd08ba5b7614a9986ed",
       "IPY_MODEL_8f841e8eff22436fae7f1cd6c8e27c32"
      ],
      "layout": "IPY_MODEL_b47f60d2de3f4bc2a4ad87d724cb5692"
     }
    },
    "8f841e8eff22436fae7f1cd6c8e27c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9e8d5d6ad65445f98b2a35449d8062c",
      "placeholder": "​",
      "style": "IPY_MODEL_2e95656870b2484cb3349386e28f0117",
      "value": "100% 440M/440M [00:38&lt;00:00, 11.4MB/s]"
     }
    },
    "97a5eb37926d4574a5a854ef1525845c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06995b0f6de4472585d340ec742e22f1",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7020148654d48eab66e9ee6eeb0c053",
      "value": 231508
     }
    },
    "9bd4a5b41a3942cd874ed08967e9d256": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3020e1a1d234b47bc2e626cf7346774",
      "placeholder": "​",
      "style": "IPY_MODEL_33784bdf13464bc8beb1b605e8304614",
      "value": "100% 361/361 [00:00&lt;00:00, 16.8kB/s]"
     }
    },
    "a503a1f1e7784f6bb0a3c38354193e8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37585d76298c4756ba1b05e103b46137",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad1c5faa41694d40946e3f2fe5d3c6a1",
      "value": 361
     }
    },
    "ad1c5faa41694d40946e3f2fe5d3c6a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b3020e1a1d234b47bc2e626cf7346774": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b47f60d2de3f4bc2a4ad87d724cb5692": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9e8d5d6ad65445f98b2a35449d8062c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7020148654d48eab66e9ee6eeb0c053": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d723e15886774886bca71d08d8023d04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9e6ceb8f1174061819d33dc0a123a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a503a1f1e7784f6bb0a3c38354193e8f",
       "IPY_MODEL_9bd4a5b41a3942cd874ed08967e9d256"
      ],
      "layout": "IPY_MODEL_6f630f60ef074ae281c9a3b63eca9bba"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
