{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"RoBERTa_qa_inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"KD6JKyGoW-3a","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('..'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gz_vXPEMHfAL","colab_type":"code","outputId":"3bd8e865-9921-4862-c889-ba5b3596e29b","executionInfo":{"status":"ok","timestamp":1580908996148,"user_tz":-480,"elapsed":3726,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!nvidia-smi"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Wed Feb  5 13:23:13 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P0    63W / 149W |   8750MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ZhO3xxuXtwR","colab_type":"code","outputId":"8dc12f7f-c887-4531-f7fb-285d9a696384","executionInfo":{"status":"ok","timestamp":1580907419258,"user_tz":-480,"elapsed":5713,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uq49afG7bPLx","colab_type":"code","outputId":"04263aba-d7e4-4dca-d1fd-6c73e5fe7297","executionInfo":{"status":"ok","timestamp":1580907441609,"user_tz":-480,"elapsed":7735,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["!pip install transformers"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"","_uuid":"","id":"QHc6btamW-3h","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import random\n","import pickle\n","import tensorflow.keras.backend as K\n","import gc\n","import time\n","import re\n","import os\n","import torch\n","from scipy.stats import spearmanr\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import KFold,StratifiedKFold\n","from scipy.stats import spearmanr\n","from math import floor, ceil\n","from transformers import AdamW,BertForSequenceClassification\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlYdOWB3W-3j","colab_type":"code","colab":{}},"source":["sample_submission = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/sample_submission.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/test.csv\")\n","train = pd.read_csv(\"/content/drive/My Drive/google-quest-challenge/train.csv\")\n","\n","MAX_SEQUENCE_LENGTH = 512"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIqdsDMrW-3l","colab_type":"code","outputId":"b2d042f3-692c-4b43-e976-08b782a80725","executionInfo":{"status":"ok","timestamp":1580909005085,"user_tz":-480,"elapsed":1000,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["print('train shape =', train.shape)\n","print('test shape =', test.shape)\n","\n","output_categories = list(train.columns[11:])\n","input_categories = list(train.columns[[1,2,5]])\n","print('\\noutput categories:\\n\\t', output_categories)\n","print('\\ninput categories:\\n\\t', input_categories)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["train shape = (6079, 41)\n","test shape = (476, 11)\n","\n","output categories:\n","\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n","\n","input categories:\n","\t ['question_title', 'question_body', 'answer']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kUxaDX5l2jaT","colab_type":"code","outputId":"8e3e3ec8-2519-4053-e512-528bcafe3719","executionInfo":{"status":"ok","timestamp":1580909006821,"user_tz":-480,"elapsed":558,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(output_categories)"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"J91XPg5D2l-G","colab_type":"code","outputId":"f296a509-05e3-46e5-ce5a-9cdb50a57e31","executionInfo":{"status":"ok","timestamp":1580909008474,"user_tz":-480,"elapsed":1277,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["output_categories[21:]"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['answer_helpful',\n"," 'answer_level_of_information',\n"," 'answer_plausible',\n"," 'answer_relevance',\n"," 'answer_satisfaction',\n"," 'answer_type_instructions',\n"," 'answer_type_procedure',\n"," 'answer_type_reason_explanation',\n"," 'answer_well_written']"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"Fw-o2_9SW-3n","colab_type":"code","colab":{}},"source":["def _get_masks(tokens, max_seq_length):\n","    \"\"\"Mask for padding\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","\n","def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            if first_sep:\n","                first_sep = False \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [1] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input_q(title, question,max_sequence_length, \n","                t_max_len=50, q_max_len=458):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","\n","    if (t_len+q_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            q_max_len = q_max_len + (t_max_len - t_len)\n","        else:\n","            t_new_len = t_max_len\n","      \n","\n","        q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+ q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","            \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","    \n","    return t, q\n","\n","\n","def _trim_input(title, question, answer, max_sequence_length, \n","                t_max_len=30, q_max_len=239, a_max_len=239):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","        \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","        if a_len > a_new_len:\n","            ind1 = floor(a_new_len/2)\n","            ind2 = ceil(a_new_len/2)\n","            a = a[:ind1]+a[-ind2:]\n","        else:\n","            a = a[:a_new_len]\n","    \n","    return t, q, a\n","\n","def _convert_to_bert_inputs(title, question, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    \n","    stoken = ['<s>'] + title + ['</s>','</s>'] + question + ['</s>']\n","\n","    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n","    input_masks = _get_masks(stoken, max_sequence_length)\n","    input_segments = _get_segments(stoken, max_sequence_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        t, q = _trim_input_q(t, q, max_sequence_length)\n","\n","        ids, masks, segments = _convert_to_bert_inputs(t, q, tokenizer, max_sequence_length)\n","        input_ids.append(ids)\n","        input_masks.append(masks)\n","        input_segments.append(segments)\n","        \n","    return [np.asarray(input_ids, dtype=np.int32), \n","            np.asarray(input_masks, dtype=np.int32), \n","            np.asarray(input_segments, dtype=np.int32)]\n","\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcJFuVXDW-3p","colab_type":"code","colab":{}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdtZohh9K1dA","colab_type":"code","colab":{}},"source":["import torch\n","\n","def hard_sigmoid(x):\n","    \"\"\"\n","    Computes element-wise hard sigmoid of x.\n","    See e.g. https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/sigm.py#L279\n","    \"\"\"\n","    x = (0.2 * x) + 0.5\n","    x = torch.clamp(x, 0.000001, 0.999999)\n","    return x\n","\n","def postProcessing(x):\n","    x = torch.tensor(x)\n","    x = torch.cat((torch.sigmoid(x[:,:2]),hard_sigmoid(x[:,2].reshape(-1,1)),torch.sigmoid(x[:,3:11]),hard_sigmoid(x[:,11:13]),\\\n","                        torch.sigmoid(x[:,13].reshape(-1,1)),hard_sigmoid(x[:,14:16]),torch.sigmoid(x[:,16:])),1)\n","    \n","    return x.numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"323A8fOJW-3r","colab_type":"code","colab":{}},"source":["class TextDataset(torch.utils.data.TensorDataset):\n","\n","    def __init__(self, x_train, idxs, targets=None):\n","        self.input_ids = x_train[0][idxs]\n","        self.input_masks = x_train[1][idxs]\n","        self.input_segments = x_train[2][idxs]\n","        self.targets = targets[idxs] if targets is not None else np.zeros((x_train[0].shape[0], 30))\n","\n","    def __getitem__(self, idx):\n","#         x_train = self.x_train[idx]\n","        input_ids =  self.input_ids[idx]\n","        input_masks = self.input_masks[idx]\n","        input_segments = self.input_segments[idx]\n","\n","        target = self.targets[idx]\n","\n","        return input_ids, input_masks, input_segments, target\n","\n","    def __len__(self):\n","        return len(self.input_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ1oU5n_W-3t","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer,BertConfig,get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup,AutoTokenizer,AutoModel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHPC2AE4CLuR","colab_type":"code","colab":{}},"source":["from transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, get_cosine_with_hard_restarts_schedule_with_warmup"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TXqSLKNW-3v","colab_type":"code","colab":{}},"source":["pretrained_weights = 'roberta-base'\n","tokenizer = RobertaTokenizer.from_pretrained('/content/drive/My Drive/RoBERTa')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFZcbly46yTe","colab_type":"code","outputId":"2f30dd9c-3d5a-41fa-d6ed-1e370a29fa29","executionInfo":{"status":"ok","timestamp":1580909018380,"user_tz":-480,"elapsed":1227,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["output_categories"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['question_asker_intent_understanding',\n"," 'question_body_critical',\n"," 'question_conversational',\n"," 'question_expect_short_answer',\n"," 'question_fact_seeking',\n"," 'question_has_commonly_accepted_answer',\n"," 'question_interestingness_others',\n"," 'question_interestingness_self',\n"," 'question_multi_intent',\n"," 'question_not_really_a_question',\n"," 'question_opinion_seeking',\n"," 'question_type_choice',\n"," 'question_type_compare',\n"," 'question_type_consequence',\n"," 'question_type_definition',\n"," 'question_type_entity',\n"," 'question_type_instructions',\n"," 'question_type_procedure',\n"," 'question_type_reason_explanation',\n"," 'question_type_spelling',\n"," 'question_well_written',\n"," 'answer_helpful',\n"," 'answer_level_of_information',\n"," 'answer_plausible',\n"," 'answer_relevance',\n"," 'answer_satisfaction',\n"," 'answer_type_instructions',\n"," 'answer_type_procedure',\n"," 'answer_type_reason_explanation',\n"," 'answer_well_written']"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"BuDlWLg060ko","colab_type":"code","colab":{}},"source":["output_categories_q = output_categories[:21]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIjNZZtr64Iw","colab_type":"code","outputId":"5105add6-9caa-4f8b-c342-dc79fa3ca95e","executionInfo":{"status":"ok","timestamp":1580909018382,"user_tz":-480,"elapsed":858,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["output_categories_q"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['question_asker_intent_understanding',\n"," 'question_body_critical',\n"," 'question_conversational',\n"," 'question_expect_short_answer',\n"," 'question_fact_seeking',\n"," 'question_has_commonly_accepted_answer',\n"," 'question_interestingness_others',\n"," 'question_interestingness_self',\n"," 'question_multi_intent',\n"," 'question_not_really_a_question',\n"," 'question_opinion_seeking',\n"," 'question_type_choice',\n"," 'question_type_compare',\n"," 'question_type_consequence',\n"," 'question_type_definition',\n"," 'question_type_entity',\n"," 'question_type_instructions',\n"," 'question_type_procedure',\n"," 'question_type_reason_explanation',\n"," 'question_type_spelling',\n"," 'question_well_written']"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"UCp7_1H-W-3x","colab_type":"code","outputId":"d5c3fd3d-54c9-4803-968f-78b920c33686","executionInfo":{"status":"ok","timestamp":1580909079385,"user_tz":-480,"elapsed":11083,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","y_train = compute_output_arrays(train, output_categories)\n","x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["6079it [00:08, 733.69it/s]\n","476it [00:00, 551.80it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cKlp16oXW-31","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import RobertaConfig, RobertaModel, RobertaForSequenceClassification, BertPreTrainedModel\n","\n","ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = {\n","    \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin\",\n","    \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin\",\n","    \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin\",\n","    \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin\",\n","    \"roberta-base-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin\",\n","    \"roberta-large-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin\",\n","}\n","\n","class CustomizedRoberta(BertPreTrainedModel):\n","    config_class = RobertaConfig\n","    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n","    base_model_prefix = \"roberta\"\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.roberta = RobertaModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.linear1 = nn.Linear(config.hidden_size*2, 21)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n","            Labels for computing the sequence classification/regression loss.\n","            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n","            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","\n","    Returns:\n","        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n","        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n","            Classification (or regression if config.num_labels==1) loss.\n","        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n","            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n","        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n","            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n","            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n","\n","            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n","        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n","            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n","            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n","\n","            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","            heads.\n","\n","    Examples::\n","\n","        from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","        import torch\n","\n","        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","        model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n","        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n","        outputs = model(input_ids, labels=labels)\n","        loss, logits = outputs[:2]\n","\n","        \"\"\"\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","        avg_pool = torch.mean(outputs[0], 1)\n","        max_pool, _ = torch.max(outputs[0], 1)\n","        pooled_output = self.dropout(torch.cat((max_pool, avg_pool), 1))\n","        logits = self.linear1(pooled_output)\n","\n","\n","        outputs = (logits,) + outputs[2:]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ITMu2nKrHqXL","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","class callback:\n","    def __init__(self):\n","        self.score = list()\n","        self.model = list()\n","        self.data = list()\n","    \n","    def put(self, model,data, score):\n","        self.score.append(score)\n","        self.model.append(model)\n","        self.data.append(data)\n","\n","    def get_model(self):\n","        ind = np.argmin(self.score)\n","        return self.model[ind]\n","    def get_data(self):\n","        ind = np.argmin(self.score)\n","        return self.data[ind]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5MhwPYxknLM","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/model0203_roberta_q.pkl\",\"rb\") as f:\n","    model_list = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"okJoN66rkvKz","colab_type":"code","outputId":"a6a3936a-32a7-4fd6-dd50-f0de30137127","executionInfo":{"status":"ok","timestamp":1580909085345,"user_tz":-480,"elapsed":11155,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(model_list)"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"0jYqd5JPW-33","colab_type":"code","outputId":"0d6c2767-d673-4903-cec9-5e0195b84d5f","executionInfo":{"status":"ok","timestamp":1580909655591,"user_tz":-480,"elapsed":580764,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["NFOLDS = 5\n","BATCH_SIZE = 4\n","EPOCHS = 4\n","SEED = 4354\n","num_warmup_steps = 100\n","lr = 3e-5\n","\n","\n","gradient_accumulation_steps = 1\n","seed_everything(SEED)\n","\n","\n","y_oof_q = np.zeros((len(train), 21))\n","test_pred_q = np.zeros((len(test), 21))\n","\n","kf = KFold(n_splits=NFOLDS, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n","    \n","\n","    print(f'fold {i+1}')\n","    gc.collect()\n","    \n","    ## loader\n","    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    net = model_list[i]\n","    net.cuda()\n","\n","\n","    valid_preds = np.zeros((len(valid_idx), 21))\n","        \n","    net.eval()\n","    for j,data in enumerate(val_loader):\n","\n","        # get the inputs\n","        input_ids, input_masks, input_segments, labels = data\n","        pred = net(input_ids = input_ids.long().cuda(),\n","                        labels = None,\n","                        attention_mask = input_masks.cuda()\n","                        )[0]\n","\n","\n","        valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n","\n","    y_oof_q[valid_idx] = valid_preds\n","    \n","    result = list()\n","\n","\n","    net.eval()\n","    with torch.no_grad():\n","        for data in test_loader:\n","            input_ids, input_masks, input_segments, labels = data\n","            y_pred = net(input_ids = input_ids.long().cuda(),\n","                                labels = None,\n","                                attention_mask = input_masks.cuda()\n","                            )[0]\n","\n","            result.extend(y_pred.cpu().detach().numpy())\n","            \n","    test_pred_q += np.array(result)/NFOLDS\n","\n","\n","        \n"],"execution_count":68,"outputs":[{"output_type":"stream","text":["fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QDCONI_-E4AS","colab_type":"code","colab":{}},"source":["def _get_masks(tokens, max_seq_length):\n","    \"\"\"Mask for padding\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n","\n","def _get_segments(tokens, max_seq_length):\n","    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n","    if len(tokens)>max_seq_length:\n","        raise IndexError(\"Token length more than max seq length!\")\n","    segments = []\n","    first_sep = True\n","    current_segment_id = 0\n","    for token in tokens:\n","        segments.append(current_segment_id)\n","        if token == \"[SEP]\":\n","            if first_sep:\n","                first_sep = False \n","            else:\n","                current_segment_id = 1\n","    return segments + [0] * (max_seq_length - len(tokens))\n","\n","\n","def _get_ids(tokens, tokenizer, max_seq_length):\n","    \"\"\"Token ids from Tokenizer vocab\"\"\"\n","    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n","    return input_ids\n","\n","def _trim_input(title, question, answer, max_sequence_length, \n","                t_max_len=30, q_max_len=239, a_max_len=239):\n","\n","    t = tokenizer.tokenize(title)\n","    q = tokenizer.tokenize(question)\n","    a = tokenizer.tokenize(answer)\n","    \n","    t_len = len(t)\n","    q_len = len(q)\n","    a_len = len(a)\n","\n","    if (t_len+q_len+a_len+4) > max_sequence_length:\n","        \n","        if t_max_len > t_len:\n","            t_new_len = t_len\n","            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n","            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n","        else:\n","            t_new_len = t_max_len\n","      \n","        if a_max_len > a_len:\n","            a_new_len = a_len \n","            q_new_len = q_max_len + (a_max_len - a_len)\n","        elif q_max_len > q_len:\n","            a_new_len = a_max_len + (q_max_len - q_len)\n","            q_new_len = q_len\n","        else:\n","            a_new_len = a_max_len\n","            q_new_len = q_max_len\n","            \n","            \n","        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n","            raise ValueError(\"New sequence length should be %d, but is %d\" \n","                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n","        \n","        if t_len > t_new_len:\n","            ind1 = floor(t_new_len/2)\n","            ind2 = ceil(t_new_len/2)\n","            t = t[:ind1]+t[-ind2:]\n","        else:\n","            t = t[:t_new_len]\n","\n","        if q_len > q_new_len:\n","            ind1 = floor(q_new_len/2)\n","            ind2 = ceil(q_new_len/2)\n","            q = q[:ind1]+q[-ind2:]\n","        else:\n","            q = q[:q_new_len]\n","\n","        if a_len > a_new_len:\n","            ind1 = floor(a_new_len/2)\n","            ind2 = ceil(a_new_len/2)\n","            a = a[:ind1]+a[-ind2:]\n","        else:\n","            a = a[:a_new_len]\n","    \n","    return t, q, a\n","\n","def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n","    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n","    \n","    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n","\n","    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n","    input_masks = _get_masks(stoken, max_sequence_length)\n","    input_segments = _get_segments(stoken, max_sequence_length)\n","\n","    return [input_ids, input_masks, input_segments]\n","\n","def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n","    input_ids, input_masks, input_segments = [], [], []\n","    for _, instance in tqdm(df[columns].iterrows()):\n","        t, q, a = instance.question_title, instance.question_body, instance.answer\n","\n","        t, q, a = _trim_input(t, q, a, max_sequence_length)\n","\n","        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n","        input_ids.append(ids)\n","        input_masks.append(masks)\n","        input_segments.append(segments)\n","        \n","    return [np.asarray(input_ids, dtype=np.int32), \n","            np.asarray(input_masks, dtype=np.int32), \n","            np.asarray(input_segments, dtype=np.int32)]\n","\n","\n","def compute_output_arrays(df, columns):\n","    return np.asarray(df[columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjgfigGaB1oG","colab_type":"code","outputId":"83594fc4-d85c-4325-f449-94cc79204453","executionInfo":{"status":"ok","timestamp":1580909673219,"user_tz":-480,"elapsed":593722,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x_train = compute_input_arays(train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","x_test = compute_input_arays(test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["6079it [00:15, 390.87it/s]\n","476it [00:01, 385.78it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NjBX7xmDB1rF","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import RobertaConfig, RobertaModel, RobertaForSequenceClassification, BertPreTrainedModel\n","\n","ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = {\n","    \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin\",\n","    \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin\",\n","    \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin\",\n","    \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin\",\n","    \"roberta-base-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin\",\n","    \"roberta-large-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin\",\n","}\n","\n","class CustomizedRoberta(BertPreTrainedModel):\n","    config_class = RobertaConfig\n","    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n","    base_model_prefix = \"roberta\"\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.roberta = RobertaModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.linear1 = nn.Linear(config.hidden_size*2, 9)\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","        r\"\"\"\n","        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n","            Labels for computing the sequence classification/regression loss.\n","            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n","            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n","            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","\n","    Returns:\n","        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n","        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n","            Classification (or regression if config.num_labels==1) loss.\n","        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n","            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n","        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n","            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n","            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n","\n","            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n","        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n","            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n","            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n","\n","            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n","            heads.\n","\n","    Examples::\n","\n","        from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","        import torch\n","\n","        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","        model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n","        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n","        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n","        outputs = model(input_ids, labels=labels)\n","        loss, logits = outputs[:2]\n","\n","        \"\"\"\n","        outputs = self.roberta(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","\n","        avg_pool = torch.mean(outputs[0], 1)\n","        max_pool, _ = torch.max(outputs[0], 1)\n","        pooled_output = self.dropout(torch.cat((max_pool, avg_pool), 1))\n","        logits = self.linear1(pooled_output)\n","\n","\n","        outputs = (logits,) + outputs[2:]\n","        if labels is not None:\n","            if self.num_labels == 1:\n","                #  We are doing regression\n","                loss_fct = MSELoss()\n","                loss = loss_fct(logits.view(-1), labels.view(-1))\n","            else:\n","                loss_fct = CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xl7qNMvRmnfx","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/model0203_roberta_a.pkl\",\"rb\") as f:\n","    model_list = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtfIA_MwmzzB","colab_type":"code","outputId":"fde91f51-d973-48c6-99a0-77ebbecb77cc","executionInfo":{"status":"ok","timestamp":1580909717011,"user_tz":-480,"elapsed":634787,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(model_list)"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"vsMtocMWln8_","colab_type":"code","outputId":"903d05da-a19a-496d-f650-b50dc00a6127","executionInfo":{"status":"ok","timestamp":1580910299514,"user_tz":-480,"elapsed":1216968,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["NFOLDS = 5\n","BATCH_SIZE = 4\n","EPOCHS = 4\n","SEED = 4354\n","num_warmup_steps = 100\n","lr = 3e-5\n","\n","\n","gradient_accumulation_steps = 1\n","seed_everything(SEED)\n","\n","\n","y_oof_a = np.zeros((len(train), 9))\n","test_pred_a = np.zeros((len(test), 9))\n","\n","kf = KFold(n_splits=NFOLDS, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(TextDataset(x_test, test.index),batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","for i, (train_idx, valid_idx) in enumerate(kf.split(x_train[0])):\n","    \n","\n","    print(f'fold {i+1}')\n","    gc.collect()\n","    \n","    ## loader\n","    val_loader = torch.utils.data.DataLoader(TextDataset(x_train, valid_idx, y_train),batch_size=BATCH_SIZE, shuffle=False)\n","    \n","\n","    net = model_list[i]\n","    net.cuda()\n","\n","\n","    valid_preds = np.zeros((len(valid_idx), 9))\n","        \n","    net.eval()\n","    for j,data in enumerate(val_loader):\n","\n","        # get the inputs\n","        input_ids, input_masks, input_segments, labels = data\n","        pred = net(input_ids = input_ids.long().cuda(),\n","                        labels = None,\n","                        attention_mask = input_masks.cuda()\n","                        )[0]\n","\n","\n","        valid_preds[j * BATCH_SIZE:(j+1) * BATCH_SIZE] = pred.cpu().detach().numpy()\n","\n","    y_oof_a[valid_idx] = valid_preds\n","    \n","    result = list()\n","\n","\n","    net.eval()\n","    with torch.no_grad():\n","        for data in test_loader:\n","            input_ids, input_masks, input_segments, labels = data\n","            y_pred = net(input_ids = input_ids.long().cuda(),\n","                                labels = None,\n","                                attention_mask = input_masks.cuda()\n","                            )[0]\n","\n","            result.extend(y_pred.cpu().detach().numpy())\n","            \n","    test_pred_a += np.array(result)/NFOLDS\n","\n","\n","        \n"],"execution_count":74,"outputs":[{"output_type":"stream","text":["fold 1\n","fold 2\n","fold 3\n","fold 4\n","fold 5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zO1bNEjdloAD","colab_type":"code","colab":{}},"source":["y_oof = np.concatenate((y_oof_q,y_oof_a), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6NY7S_-loG6","colab_type":"code","colab":{}},"source":["test_pred = np.concatenate((test_pred_q,test_pred_a), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hoKh96OKhsEk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssI421sZhsMK","colab_type":"code","colab":{}},"source":["with open(\"/content/drive/My Drive/qa_model/y_oof_roberta.pkl\",\"wb\") as f:\n","    pickle.dump(y_oof,f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DOJB5DghsQs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBmxl3QghsKo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-uzG2UrhsIV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3ynHpGaloFI","colab_type":"code","colab":{}},"source":["test_pred.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"slY5bSroloDo","colab_type":"code","colab":{}},"source":["y_oof.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZV_lojTANFD","colab_type":"code","colab":{}},"source":["def postProcessing(x):\n","\n","    def f_0(x):\n","        if x <= 0.1666:\n","            x = 0.0000001\n","        if x >= 0.833:\n","            x = 0.99999999\n","        return x\n","\n","    def f_1(x):\n","        if x <= 0.1666:\n","            x = 0.00000001\n","        # if x >= 0.8333:\n","        #     x = 0.99999999\n","        return x\n","\n","    x[:,2] = np.array(list(map(f_0,x[:,2])))\n","    x[:,5] = np.array(list(map(f_0,x[:,5])))\n","    x[:,11] = np.array(list(map(f_0,x[:,11])))\n","    x[:,15] = np.array(list(map(f_0,x[:,15])))\n","\n","    x[:,8] = np.array(list(map(f_1,x[:,8])))\n","    x[:,12] = np.array(list(map(f_1,x[:,12])))\n","    x[:,14] = np.array(list(map(f_1,x[:,14])))\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLhqgUD9G7JI","colab_type":"code","colab":{}},"source":["def f_0(x):\n","        if x <= 0.1666:\n","            x = 0.0000001\n","        if x >= 0.833:\n","            x = 0.99999999\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lb-bW-trB10Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"outputId":"1fc79a2f-c06d-4e6b-c6d9-b2c2d8683f31","executionInfo":{"status":"error","timestamp":1580907426725,"user_tz":-480,"elapsed":2100,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}}},"source":["a = torch.sigmoid(torch.tensor(y_oof)).numpy()"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7033062f730e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_oof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'y_oof' is not defined"]}]},{"cell_type":"code","metadata":{"id":"B3zBJE0cHxW9","colab_type":"code","colab":{}},"source":["a[:,13] = np.array(list(map(f_0,a[:,13])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HitgraunG9lK","colab_type":"code","colab":{}},"source":["a = hard_sigmoid(torch.tensor(y_oof))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mSZKp-KIB_I","colab_type":"code","outputId":"ea392988-e939-4c5c-f215-2deef5d61f24","executionInfo":{"status":"ok","timestamp":1580902395487,"user_tz":-480,"elapsed":1354,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["spearmanr(y_train[:, 13], a[:, 13]).correlation"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.20255582301617409"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"OAVpDxexHnIc","colab_type":"code","outputId":"7b29e410-7a6d-4fbb-ab56-64c70e8c8dff","executionInfo":{"status":"ok","timestamp":1580902286764,"user_tz":-480,"elapsed":3710,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["spearmanr(y_train[:, 13], a[:, 13]).correlation"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.20980806104569558"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"icrntLbBG9qF","colab_type":"code","outputId":"86b3aa6a-ce5a-4226-e000-a4f369b1a055","executionInfo":{"status":"ok","timestamp":1580902216355,"user_tz":-480,"elapsed":4879,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["spearmanr(y_train[:, 13], a[:, 13]).correlation"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.17676696307738426"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"X_-MUjFAG9oe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPYJu4LbA1qW","colab_type":"code","outputId":"a10050dc-50bf-4eef-e766-daa607a2d8e9","executionInfo":{"status":"ok","timestamp":1580902089520,"user_tz":-480,"elapsed":1506,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["a"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 3.2326,  1.4640, -1.2751,  ..., -1.7468,  1.3681,  2.1423],\n","        [ 3.1399,  1.6450, -3.9002,  ..., -5.3079, -0.6503,  2.3483],\n","        [ 2.1319, -0.5572, -5.0416,  ..., -0.8787,  1.4793,  2.3981],\n","        ...,\n","        [ 2.1425,  0.6928, -5.3844,  ..., -1.8835,  0.3801,  1.2380],\n","        [ 2.2436,  0.7396,  0.8859,  ..., -3.3095,  1.9918,  2.8196],\n","        [ 3.8875,  1.5113, -2.0171,  ..., -4.0199,  2.1642,  2.3808]],\n","       dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"9lWSqYF0Abpc","colab_type":"code","outputId":"091a1162-ba66-41b6-c617-f6e95512978e","executionInfo":{"status":"ok","timestamp":1580833404929,"user_tz":-480,"elapsed":877,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["a = postProcessing(a)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  del sys.path[0]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vWYS2xohfu4i","colab_type":"code","colab":{}},"source":["oof_score = 0\n","for i in range(30):\n","    oof_score += np.nan_to_num(\n","            spearmanr(y_train[:, i], y_oof[:, i]).correlation / 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WfM3a94Arrj","colab_type":"code","outputId":"3c8051d9-8df3-44b0-9908-e3665798db82","executionInfo":{"status":"ok","timestamp":1580910331115,"user_tz":-480,"elapsed":2587,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":79,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.40207806909928145\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AwXPZGI7AZyh","colab_type":"code","outputId":"606c6481-7ed9-4459-9d8b-4a4ad426d64c","executionInfo":{"status":"ok","timestamp":1580833315963,"user_tz":-480,"elapsed":1665,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.4272448191760734\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bxx6YCuK3uMO","colab_type":"code","outputId":"6aa64012-b957-47a7-8795-61e5fe2d16ad","executionInfo":{"status":"ok","timestamp":1580833227731,"user_tz":-480,"elapsed":790,"user":{"displayName":"林得恩","photoUrl":"","userId":"04392292192246187493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"Out of folds score = {}\",oof_score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Out of folds score = {} 0.4020780273694078\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VViu-mZKW-34","colab_type":"code","colab":{}},"source":["sample_submission.loc[:, output_categories] = test_pred\n","sample_submission.to_csv('/content/drive/My Drive/qa_submission/submission0203.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfbvM2hrtVwY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EsV2jETOtVzn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxq_DrlrtV22","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"54btDlYKtV7j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"neFkUDqytV-m","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXuxQAKptV6D","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hrw-Bmdc-7hJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}